{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#import scipy as sp\n",
    "#import matplotlib as mpl\n",
    "#import matplotlib.cm as cm\n",
    "#import matplotlib.pyplot as plt\n",
    "#import pandas as pd\n",
    "#import time\n",
    "#pd.set_option('display.width', 500)\n",
    "#pd.set_option('display.max_columns', 100)\n",
    "#pd.set_option('display.notebook_repr_html', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Based on SymSpell:\n",
    "\n",
    "Originally written in C#:\n",
    "\n",
    "// SymSpell: 1 million times faster through Symmetric Delete spelling correction algorithm\n",
    "//\n",
    "// The Symmetric Delete spelling correction algorithm reduces the complexity of edit candidate generation and dictionary lookup \n",
    "// for a given Damerau-Levenshtein distance. It is six orders of magnitude faster and language independent.\n",
    "// Opposite to other algorithms only deletes are required, no transposes + replaces + inserts.\n",
    "// Transposes + replaces + inserts of the input term are transformed into deletes of the dictionary term.\n",
    "// Replaces and inserts are expensive and language dependent: e.g. Chinese has 70,000 Unicode Han characters!\n",
    "//\n",
    "// Copyright (C) 2015 Wolf Garbe\n",
    "// Version: 3.0\n",
    "// Author: Wolf Garbe <wolf.garbe@faroo.com>\n",
    "// Maintainer: Wolf Garbe <wolf.garbe@faroo.com>\n",
    "// URL: http://blog.faroo.com/2012/06/07/improved-edit-distance-based-spelling-correction/\n",
    "// Description: http://blog.faroo.com/2012/06/07/improved-edit-distance-based-spelling-correction/\n",
    "//\n",
    "// License:\n",
    "// This program is free software; you can redistribute it and/or modify\n",
    "// it under the terms of the GNU Lesser General Public License, \n",
    "// version 3.0 (LGPL-3.0) as published by the Free Software Foundation.\n",
    "// http://www.opensource.org/licenses/LGPL-3.0\n",
    "//\n",
    "// Usage: single word + Enter:  Display spelling suggestions\n",
    "//        Enter without input:  Terminate the program\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import re, collections\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_edit_distance = 3\n",
    "dictionary = {}\n",
    "longest_word_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_deletes_list(w):\n",
    "    '''given a word, derive strings with up to max_edit_distance characters deleted'''\n",
    "    deletes = []\n",
    "    queue = [w]\n",
    "    for d in range(max_edit_distance):\n",
    "        temp_queue = []\n",
    "        for word in queue:\n",
    "            if len(word)>1:\n",
    "                for c in range(len(word)):  # character index\n",
    "                    word_minus_c = word[:c] + word[c+1:]\n",
    "                    if word_minus_c not in deletes:\n",
    "                        deletes.append(word_minus_c)\n",
    "                    if word_minus_c not in temp_queue:\n",
    "                        temp_queue.append(word_minus_c)\n",
    "        queue = temp_queue\n",
    "        \n",
    "    return deletes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get_deletes_list(\"tomorrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dictionary_entry(w):\n",
    "    '''add word and its derived deletions to dictionary'''\n",
    "    # check if word is already in dictionary\n",
    "    # dictionary entries are in the form: (list of suggested corrections, frequency of word in corpus)\n",
    "    global longest_word_length\n",
    "    new_real_word_added = False\n",
    "    if w in dictionary:\n",
    "        dictionary[w] = (dictionary[w][0], dictionary[w][1] + 1)  # increment count of word in corpus\n",
    "    else:\n",
    "        dictionary[w] = ([], 1)  \n",
    "        longest_word_length = max(longest_word_length, len(w))\n",
    "        \n",
    "    if dictionary[w][1]==1:\n",
    "        # first appearance of word in corpus\n",
    "        # n.b. word may already be in dictionary as a derived word (deleting character from a real word)\n",
    "        # but counter of frequency of word in corpus is not incremented in those cases)\n",
    "        new_real_word_added = True\n",
    "        deletes = get_deletes_list(w)\n",
    "        for item in deletes:\n",
    "            if item in dictionary:\n",
    "                # add (correct) word to delete's suggested correction list if not already there\n",
    "                if item not in dictionary[item][0]:\n",
    "                    dictionary[item][0].append(w)\n",
    "            else:\n",
    "                dictionary[item] = ([w], 0)  # note frequency of word in corpus is not incremented\n",
    "        \n",
    "    return new_real_word_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dictionary(fname):\n",
    "    word_count = 0\n",
    "    print \"Creating dictionary...\" \n",
    "    \n",
    "    with open(fname) as file:    \n",
    "        for line in file:\n",
    "            words = re.findall('[a-z]+', line.lower())  # separate by words by non-alphabetical characters      \n",
    "            for word in words:\n",
    "                if create_dictionary_entry(word):\n",
    "                    word_count += 1\n",
    "                    \n",
    "    print \"total unique words in corpus: %i\" % word_count\n",
    "    print \"total items in dictionary (corpus words and deletions): %i\" % len(dictionary)\n",
    "    print \"  edit distance for deletions: %i\" % max_edit_distance\n",
    "    print \"  length of longest word in corpus: %i\" % longest_word_length\n",
    "        \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dictionary...\n",
      "total unique words in corpus: 29157\n",
      "total items in dictionary (corpus words and deletions): 2151998\n",
      "  edit distance for deletions: 3\n",
      "  length of longest word in corpus: 18\n",
      "CPU times: user 26.1 s, sys: 513 ms, total: 26.6 s\n",
      "Wall time: 26.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "create_dictionary(\"/Users/K-Lo/Desktop/big.txt\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>For testing:</b> <p>\n",
    "Can look up a specific entry in the dictionary below. <br>\n",
    "shows (possible corrections, and frequency that entry itself is in corpus - 0 if not a real word) <br>\n",
    "Note: will return key error if there are no corrections (because we are accessing dictionary directly here)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['essentially', 'essentials'], 92)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[\"essential\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['wrack'], 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[\"wack\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dameraulevenshtein(seq1, seq2):\n",
    "    \"\"\"Calculate the Damerau-Levenshtein distance between sequences.\n",
    "\n",
    "    Source: http://mwh.geek.nz/2009/04/26/python-damerau-levenshtein-distance/\n",
    "    \n",
    "    This distance is the number of additions, deletions, substitutions,\n",
    "    and transpositions needed to transform the first sequence into the\n",
    "    second. Although generally used with strings, any sequences of\n",
    "    comparable objects will work.\n",
    "\n",
    "    Transpositions are exchanges of *consecutive* characters; all other\n",
    "    operations are self-explanatory.\n",
    "\n",
    "    This implementation is O(N*M) time and O(M) space, for N and M the\n",
    "    lengths of the two sequences.\n",
    "\n",
    "    >>> dameraulevenshtein('ba', 'abc')\n",
    "    2\n",
    "    >>> dameraulevenshtein('fee', 'deed')\n",
    "    2\n",
    "\n",
    "    It works with arbitrary sequences too:\n",
    "    >>> dameraulevenshtein('abcd', ['b', 'a', 'c', 'd', 'e'])\n",
    "    2\n",
    "    \"\"\"\n",
    "    # codesnippet:D0DE4716-B6E6-4161-9219-2903BF8F547F\n",
    "    # Conceptually, this is based on a len(seq1) + 1 * len(seq2) + 1 matrix.\n",
    "    # However, only the current and two previous rows are needed at once,\n",
    "    # so we only store those.\n",
    "    oneago = None\n",
    "    thisrow = range(1, len(seq2) + 1) + [0]\n",
    "    for x in xrange(len(seq1)):\n",
    "        # Python lists wrap around for negative indices, so put the\n",
    "        # leftmost column at the *end* of the list. This matches with\n",
    "        # the zero-indexed strings and saves extra calculation.\n",
    "        twoago, oneago, thisrow = oneago, thisrow, [0] * len(seq2) + [x + 1]\n",
    "        for y in xrange(len(seq2)):\n",
    "            delcost = oneago[y] + 1\n",
    "            addcost = thisrow[y - 1] + 1\n",
    "            subcost = oneago[y - 1] + (seq1[x] != seq2[y])\n",
    "            thisrow[y] = min(delcost, addcost, subcost)\n",
    "            # This block deals with transpositions\n",
    "            if (x > 0 and y > 0 and seq1[x] == seq2[y - 1]\n",
    "                and seq1[x-1] == seq2[y] and seq1[x] != seq2[y]):\n",
    "                thisrow[y] = min(thisrow[y], twoago[y - 2] + 1)\n",
    "    return thisrow[len(seq2) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_suggestions(string, silent=False):\n",
    "    '''return list of suggested corrections for potentially incorrectly spelled word'''\n",
    "    if (len(string) - longest_word_length) > max_edit_distance:\n",
    "        if not silent:\n",
    "            print \"no items in dictionary within maximum edit distance\"\n",
    "        return []\n",
    "    \n",
    "    # suggestions = []\n",
    "    # s_dictionary = {}\n",
    "    suggest_dict = {}\n",
    "    \n",
    "    queue = [string]\n",
    "    q_dictionary = {}  # items other than string that we've checked\n",
    "    \n",
    "    while len(queue)>0:\n",
    "        q_item = queue[0]  # pop\n",
    "        # print \"processing '%s'\" % q_item\n",
    "        queue = queue[1:]\n",
    "        \n",
    "        # process queue item\n",
    "        if (q_item in dictionary) and (q_item not in suggest_dict):\n",
    "            if (dictionary[q_item][1]>0):\n",
    "            # word is in dictionary, and is a word from the corpus, and not already in suggestion list\n",
    "            # so add to suggestion dictionary, indexed by the word with value (frequency in corpus, edit distance)\n",
    "            # note q_items that are not the input string are shorter than input string \n",
    "            # since only deletes are added (unless manual dictionary corrections are added)\n",
    "                assert len(string)>=len(q_item)\n",
    "                suggest_dict[q_item] = (dictionary[q_item][1], len(string) - len(q_item))\n",
    "            \n",
    "            ## the suggested corrections for q_item as stored in dictionary (whether or not\n",
    "            ## q_item itself is a valid word or merely a delete) can be valid corrections\n",
    "            for sc_item in dictionary[q_item][0]:\n",
    "                if (sc_item not in suggest_dict):\n",
    "                    # compute edit distance\n",
    "                    # if len(sc_item)==len(q_item):\n",
    "                    #    item_dist = len(string) - len(q_item)\n",
    "                    # suggested items should always be longer (unless manual corrections are added)\n",
    "                    assert len(sc_item)>len(q_item)\n",
    "                    # q_items that are not input should be shorter than original string \n",
    "                    # (unless manual corrections added)\n",
    "                    assert len(q_item)<=len(string)\n",
    "                    if len(q_item)==len(string):\n",
    "                        assert q_item==string\n",
    "                        item_dist = len(sc_item) - len(q_item)\n",
    "                    #elif len(q_item)==len(string):\n",
    "                        # a suggestion could be longer or shorter than original string (bug in original FAROO?)\n",
    "                        # if suggestion is from string's suggestion list, sc_item will be longer\n",
    "                        # if suggestion is from a delete's suggestion list, sc_item may be shorter\n",
    "                    #   item_dist = abs(len(sc_item) - len(q_item))\n",
    "                    #else:\n",
    "                    # check in original code, but probably not necessary because string has already checked\n",
    "                    assert sc_item!=string\n",
    "                    \n",
    "                    # calculate edit distance using, for example, Damerau-Levenshtein distance\n",
    "                    item_dist = dameraulevenshtein(sc_item, string)\n",
    "                    \n",
    "                    if item_dist<=max_edit_distance:\n",
    "                        assert sc_item in dictionary  # should already be in dictionary if in suggestion list\n",
    "                        suggest_dict[sc_item] = (dictionary[sc_item][1], item_dist)\n",
    "        \n",
    "        # now generate deletes (e.g. a substring of string or of a delete) from the queue item\n",
    "        # as additional items to check -- add to end of queue\n",
    "        assert len(string)>=len(q_item)\n",
    "        if (len(string)-len(q_item))<max_edit_distance and len(q_item)>1:\n",
    "            for c in range(len(q_item)): # character index        \n",
    "                word_minus_c = q_item[:c] + q_item[c+1:]\n",
    "                if word_minus_c not in q_dictionary:\n",
    "                    queue.append(word_minus_c)\n",
    "                    q_dictionary[word_minus_c] = None  # arbitrary value, just to identify we checked this\n",
    "             \n",
    "    # queue is now empty: convert suggestions in dictionary to list for output\n",
    "    \n",
    "    if not silent:\n",
    "        print \"number of possible corrections: %i\" %len(suggest_dict)\n",
    "        print \"  edit distance for deletions: %i\" % max_edit_distance\n",
    "    \n",
    "    # output option 1\n",
    "    # sort results by ascending order of edit distance and descending order of frequency\n",
    "    #     and return list of suggested corrections only:\n",
    "    # return sorted(suggest_dict, key = lambda x: (suggest_dict[x][1], -suggest_dict[x][0]))\n",
    "\n",
    "    # output option 2\n",
    "    # return list of suggestions with (correction, (frequency in corpus, edit distance)):\n",
    "    as_list = suggest_dict.items()\n",
    "    return sorted(as_list, key = lambda (term, (freq, dist)): (dist, -freq))\n",
    "\n",
    "    '''\n",
    "    Option 1:\n",
    "    get_suggestions(\"file\")\n",
    "    ['file', 'five', 'fire', 'fine', ...]\n",
    "    \n",
    "    Option 2:\n",
    "    get_suggestions(\"file\")\n",
    "    [('file', (5, 0)),\n",
    "     ('five', (67, 1)),\n",
    "     ('fire', (54, 1)),\n",
    "     ('fine', (17, 1))...]  \n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>For testing:</b><p>\n",
    "Type in word to correct below, to test and get whole list of possible suggestions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of possible corrections: 103\n",
      "  edit distance for deletions: 3\n",
      "CPU times: user 20 ms, sys: 7.7 ms, total: 27.7 ms\n",
      "Wall time: 22.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('matters', (136, 2)),\n",
       " ('bitten', (13, 2)),\n",
       " ('kitten', (7, 2)),\n",
       " ('listens', (2, 2)),\n",
       " ('battens', (1, 2)),\n",
       " ('smitten', (1, 2)),\n",
       " ('matter', (365, 3)),\n",
       " ('sitting', (269, 3)),\n",
       " ('minutes', (146, 3)),\n",
       " ('written', (117, 3)),\n",
       " ('miles', (110, 3)),\n",
       " ('citizens', (109, 3)),\n",
       " ('letters', (108, 3)),\n",
       " ('listen', (100, 3)),\n",
       " ('cities', (77, 3)),\n",
       " ('bitter', (47, 3)),\n",
       " ('masters', (37, 3)),\n",
       " ('intense', (34, 3)),\n",
       " ('witness', (33, 3)),\n",
       " ('attend', (29, 3)),\n",
       " ('mistress', (24, 3)),\n",
       " ('fitted', (23, 3)),\n",
       " ('mines', (22, 3)),\n",
       " ('fitting', (21, 3)),\n",
       " ('miners', (19, 3)),\n",
       " ('mitenka', (16, 3)),\n",
       " ('tens', (16, 3)),\n",
       " ('sisters', (16, 3)),\n",
       " ('intent', (13, 3)),\n",
       " ('mothers', (12, 3)),\n",
       " ('mutton', (11, 3)),\n",
       " ('bites', (10, 3)),\n",
       " ('sites', (9, 3)),\n",
       " ('omitted', (9, 3)),\n",
       " ('buttons', (8, 3)),\n",
       " ('fitness', (8, 3)),\n",
       " ('rotten', (8, 3)),\n",
       " ('attends', (8, 3)),\n",
       " ('matrena', (8, 3)),\n",
       " ('intend', (8, 3)),\n",
       " ('titles', (7, 3)),\n",
       " ('pitted', (6, 3)),\n",
       " ('matted', (6, 3)),\n",
       " ('omitting', (5, 3)),\n",
       " ('intends', (5, 3)),\n",
       " ('witted', (5, 3)),\n",
       " ('kitchens', (5, 3)),\n",
       " ('hitting', (5, 3)),\n",
       " ('emitted', (4, 3)),\n",
       " ('items', (4, 3)),\n",
       " ('mutter', (4, 3)),\n",
       " ('pitting', (4, 3)),\n",
       " ('mates', (4, 3)),\n",
       " ('emitting', (3, 3)),\n",
       " ('litter', (3, 3)),\n",
       " ('dites', (3, 3)),\n",
       " ('mister', (2, 3)),\n",
       " ('distend', (2, 3)),\n",
       " ('softens', (2, 3)),\n",
       " ('withers', (2, 3)),\n",
       " ('motions', (2, 3)),\n",
       " ('cutters', (2, 3)),\n",
       " ('mien', (2, 3)),\n",
       " ('linens', (2, 3)),\n",
       " ('mints', (2, 3)),\n",
       " ('hastens', (2, 3)),\n",
       " ('gotten', (2, 3)),\n",
       " ('misses', (2, 3)),\n",
       " ('dickens', (2, 3)),\n",
       " ('viens', (2, 3)),\n",
       " ('winters', (2, 3)),\n",
       " ('matins', (2, 3)),\n",
       " ('potters', (2, 3)),\n",
       " ('amiens', (1, 3)),\n",
       " ('metes', (1, 3)),\n",
       " ('filters', (1, 3)),\n",
       " ('pickens', (1, 3)),\n",
       " ('distends', (1, 3)),\n",
       " ('kittenish', (1, 3)),\n",
       " ('gutters', (1, 3)),\n",
       " ('rioters', (1, 3)),\n",
       " ('hatters', (1, 3)),\n",
       " ('sittings', (1, 3)),\n",
       " ('moyens', (1, 3)),\n",
       " ('fetters', (1, 3)),\n",
       " ('fatten', (1, 3)),\n",
       " ('remittent', (1, 3)),\n",
       " ('imitates', (1, 3)),\n",
       " ('mattress', (1, 3)),\n",
       " ('pities', (1, 3)),\n",
       " ('utters', (1, 3)),\n",
       " ('athens', (1, 3)),\n",
       " ('maidens', (1, 3)),\n",
       " ('tiens', (1, 3)),\n",
       " ('matting', (1, 3)),\n",
       " ('milton', (1, 3)),\n",
       " ('mists', (1, 3)),\n",
       " ('hittel', (1, 3)),\n",
       " ('cottons', (1, 3)),\n",
       " ('intents', (1, 3)),\n",
       " ('midges', (1, 3)),\n",
       " ('wotten', (1, 3)),\n",
       " ('patterns', (1, 3))]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_suggestions(\"mittens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#benchmark timing\n",
    "for i in range(1000):\n",
    "    get_suggestions(\"acamodation\", silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#benchmark timing\n",
    "for i in range(1000):\n",
    "    get_suggestions(\"acomodation\", silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#benchmark timing\n",
    "for i in range(1000):\n",
    "    get_suggestions(\"hous\", silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get best word\n",
    "def best_word(s, silent=False):\n",
    "    try:\n",
    "        return get_suggestions(s, silent)[0]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>For testing:</b><p>\n",
    "Type in word to correct below, to test and get most suggested word.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of possible corrections: 337\n",
      "  edit distance for deletions: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('hello', (1, 0))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_word(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct_document(fname):\n",
    "    with open(fname) as file:\n",
    "        doc_word_count = 0\n",
    "        corrected_word_count = 0\n",
    "        unknown_word_count = 0\n",
    "        print \"Finding misspelled words in your document...\" \n",
    "        \n",
    "        for i, line in enumerate(file):\n",
    "            doc_words = re.findall('[a-z]+', line.lower())  # separate by words by non-alphabetical characters      \n",
    "            for doc_word in doc_words:\n",
    "                doc_word_count += 1\n",
    "                suggestion = best_word(doc_word, silent=True)\n",
    "                if suggestion is None:\n",
    "                    print \"In line %i, the word < %s > was not found (no suggested correction)\" % (i, doc_word)\n",
    "                    unknown_word_count += 1\n",
    "                elif suggestion[0]!=doc_word:\n",
    "                    print \"In line %i, %s: suggested correction is < %s >\" % (i, doc_word, suggestion[0])\n",
    "                    corrected_word_count += 1\n",
    "        \n",
    "    print \"-----\"\n",
    "    print \"total words checked: %i\" % doc_word_count\n",
    "    print \"total unknown words: %i\" % unknown_word_count\n",
    "    print \"total potential errors found: %i\" % corrected_word_count\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>For testing:</b><p>\n",
    "Provide text file to correct, and give all best word suggestions (word level only) for errors.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding misspelled words in your document...\n",
      "-----\n",
      "total words checked: 16\n",
      "total unknown words: 0\n",
      "total potential errors found: 0\n"
     ]
    }
   ],
   "source": [
    "correct_document(\"/Users/K-Lo/Desktop/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding misspelled words in your document...\n",
      "In line 3, taiths: suggested correction is < faith >\n",
      "In line 11, the word < oonipiittee > was not found (no suggested correction)\n",
      "In line 13, tj: suggested correction is < to >\n",
      "In line 13, mnnff: suggested correction is < snuff >\n",
      "In line 13, gjpt: suggested correction is < get >\n",
      "In line 15, bh: suggested correction is < by >\n",
      "In line 15, snc: suggested correction is < sac >\n",
      "In line 15, uth: suggested correction is < th >\n",
      "In line 15, unuer: suggested correction is < under >\n",
      "In line 20, mthiitt: suggested correction is < thirty >\n",
      "In line 21, cas: suggested correction is < was >\n",
      "In line 22, pythian: suggested correction is < scythian >\n",
      "In line 26, brainin: suggested correction is < brain >\n",
      "In line 27, jfl: suggested correction is < of >\n",
      "In line 28, ji: suggested correction is < i >\n",
      "In line 28, stice: suggested correction is < stick >\n",
      "In line 28, blaci: suggested correction is < black >\n",
      "In line 28, eug: suggested correction is < dug >\n",
      "In line 28, debbs: suggested correction is < debts >\n",
      "In line 29, nericans: suggested correction is < americans >\n",
      "In line 30, ainin: suggested correction is < again >\n",
      "In line 30, ergs: suggested correction is < eggs >\n",
      "In line 31, trumped: suggested correction is < trumpet >\n",
      "In line 32, erican: suggested correction is < american >\n",
      "In line 33, unorthodox: suggested correction is < orthodox >\n",
      "In line 33, nenance: suggested correction is < penance >\n",
      "In line 33, thg: suggested correction is < the >\n",
      "In line 34, sln: suggested correction is < son >\n",
      "In line 34, rgs: suggested correction is < rags >\n",
      "In line 38, williaij: suggested correction is < william >\n",
      "In line 38, eu: suggested correction is < e >\n",
      "In line 40, fcsf: suggested correction is < ff >\n",
      "In line 40, ber: suggested correction is < be >\n",
      "In line 42, unorthodoxy: suggested correction is < orthodox >\n",
      "In line 42, thpt: suggested correction is < that >\n",
      "In line 42, the word < senbrnrgs > was not found (no suggested correction)\n",
      "In line 44, fascism: suggested correction is < fascia >\n",
      "In line 62, loo: suggested correction is < look >\n",
      "In line 65, ththn: suggested correction is < then >\n",
      "In line 65, scbell: suggested correction is < bell >\n",
      "In line 65, ife: suggested correction is < if >\n",
      "In line 65, yktcn: suggested correction is < skin >\n",
      "In line 65, thl: suggested correction is < the >\n",
      "In line 66, thi: suggested correction is < the >\n",
      "In line 68, saij: suggested correction is < said >\n",
      "In line 69, defendants: suggested correction is < defendant >\n",
      "In line 69, cornr: suggested correction is < corner >\n",
      "In line 69, nists: suggested correction is < fists >\n",
      "In line 72, ro: suggested correction is < to >\n",
      "In line 74, ath: suggested correction is < at >\n",
      "In line 75, tti: suggested correction is < ti >\n",
      "In line 75, rg: suggested correction is < re >\n",
      "In line 75, acrific: suggested correction is < pacific >\n",
      "In line 77, korea: suggested correction is < more >\n",
      "In line 78, ro: suggested correction is < to >\n",
      "In line 78, doatli: suggested correction is < death >\n",
      "In line 81, ith: suggested correction is < it >\n",
      "In line 81, ry: suggested correction is < by >\n",
      "In line 81, kl: suggested correction is < ll >\n",
      "In line 81, ech: suggested correction is < each >\n",
      "In line 82, rb: suggested correction is < re >\n",
      "In line 82, the word < ghmhvestigat > was not found (no suggested correction)\n",
      "In line 82, nb: suggested correction is < no >\n",
      "In line 82, rg: suggested correction is < re >\n",
      "In line 83, rosenbt: suggested correction is < rodent >\n",
      "In line 83, rgs: suggested correction is < rags >\n",
      "In line 84, coriritted: suggested correction is < committed >\n",
      "In line 86, fighti: suggested correction is < fight >\n",
      "In line 88, bths: suggested correction is < baths >\n",
      "In line 88, tchf: suggested correction is < the >\n",
      "In line 91, ro: suggested correction is < to >\n",
      "In line 91, ijb: suggested correction is < in >\n",
      "In line 92, telegrnm: suggested correction is < telegram >\n",
      "In line 92, jillia: suggested correction is < william >\n",
      "In line 92, patt: suggested correction is < part >\n",
      "In line 92, rson: suggested correction is < son >\n",
      "In line 93, ecretdry: suggested correction is < secretary >\n",
      "In line 95, purview: suggested correction is < purves >\n",
      "In line 95, rder: suggested correction is < order >\n",
      "In line 99, gor: suggested correction is < for >\n",
      "In line 99, dthethg: suggested correction is < teeth >\n",
      "In line 99, ared: suggested correction is < are >\n",
      "In line 99, ro: suggested correction is < to >\n",
      "In line 99, enb: suggested correction is < end >\n",
      "In line 99, rg: suggested correction is < re >\n",
      "In line 100, sacc: suggested correction is < sac >\n",
      "In line 100, vthnz: suggested correction is < the >\n",
      "In line 100, dri: suggested correction is < dry >\n",
      "In line 100, yfu: suggested correction is < you >\n",
      "In line 101, ile: suggested correction is < ill >\n",
      "In line 101, rosi: suggested correction is < rose >\n",
      "In line 101, rg: suggested correction is < re >\n",
      "In line 102, fnir: suggested correction is < fair >\n",
      "In line 102, jhy: suggested correction is < why >\n",
      "In line 102, azi: suggested correction is < ami >\n",
      "In line 103, fascist: suggested correction is < fascia >\n",
      "In line 104, nb: suggested correction is < no >\n",
      "-----\n",
      "total words checked: 700\n",
      "total unknown words: 3\n",
      "total potential errors found: 94\n"
     ]
    }
   ],
   "source": [
    "# from http://www.columbia.edu/acis/cria/rosenberg/sample/\n",
    "correct_document(\"/Users/K-Lo/Desktop/OCRsample.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Serial code for context-based improvement <p>\n",
    "Using same corpus to generate, but could consider pre-manufactured lists<br>\n",
    "Could integrate with code above when generating main dictionary\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_of_two = {}\n",
    "first_counts = {}\n",
    "last_of_two = {}\n",
    "last_2counts = {}\n",
    "last_of_three = {}\n",
    "last_3counts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_trigram_dict(fname):\n",
    "    '''creates bigram dictionaries, and 1 trigram dictionary for (__, __, word)'''\n",
    "    word_count = 0\n",
    "    print \"Creating trigram database...\" \n",
    "    \n",
    "    word1 = \"\"\n",
    "    word2 = \"\"\n",
    "    \n",
    "    with open(fname) as file:    \n",
    "        for line in file:\n",
    "            words = re.findall('[a-z]+', line.lower())  # separate by words by non-alphabetical characters      \n",
    "            for word in words:\n",
    "                word_count += 1\n",
    "                if len(word1)==0:\n",
    "                    word1 = word\n",
    "                elif len(word2)==0:\n",
    "                    word2 = word\n",
    "                    first_of_two[word1] = [word2]\n",
    "                    first_counts[word1 + \" \" + word2] = 1\n",
    "                    last_of_two[word2] = [word1]\n",
    "                    last_2counts[word1 + \" \" + word2] = 1\n",
    "                else:\n",
    "                    #third word onwards\n",
    "                    if word2 in first_of_two:\n",
    "                        if word in first_of_two[word2]:\n",
    "                            first_counts[word2 + \" \" + word] += 1\n",
    "                        else:\n",
    "                            first_of_two[word2].append(word)\n",
    "                            first_counts[word2 + \" \" + word] = 1\n",
    "                    else:\n",
    "                        first_of_two[word2] = [word]\n",
    "                        first_counts[word2 + \" \" + word] = 1\n",
    "                        \n",
    "                    if word in last_of_two:\n",
    "                        if word2 in last_of_two[word]:\n",
    "                            last_2counts[word2 + \" \" + word] += 1\n",
    "                        else:\n",
    "                            last_of_two[word].append(word2)\n",
    "                            last_2counts[word2 + \" \" + word] = 1\n",
    "                    else:\n",
    "                        last_of_two[word] = [word2]\n",
    "                        last_2counts[word2 + \" \" + word] = 1\n",
    "                        \n",
    "                    back_two = word1 + \" \" + word2\n",
    "                    if word in last_of_three:\n",
    "                        if back_two in last_of_three[word]:\n",
    "                            last_3counts[back_two + \" \" + word] += 1\n",
    "                        else:\n",
    "                            last_of_three[word].append(back_two)\n",
    "                            last_3counts[back_two + \" \" + word] = 1\n",
    "                    else:\n",
    "                        last_of_three[word] = [back_two]\n",
    "                        last_3counts[back_two + \" \" + word] = 1\n",
    "                    \n",
    "                    #increment words\n",
    "                    word1 = word2\n",
    "                    word2 = word\n",
    "    \n",
    "    print \"total unique words in corpus: %i\" % word_count\n",
    "    print \"total number of unique first words of a pair: %i\" % len(first_counts)\n",
    "    print \"total number of unique second words of a pair: %i\" % len(last_2counts)\n",
    "    print \"total number of unique last words of a trigram: %i\" % len(last_3counts)\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating trigram database...\n",
      "total unique words in corpus: 1105285\n",
      "total number of unique first words of a pair: 378951\n",
      "total number of unique second words of a pair: 378951\n",
      "total number of unique last words of a trigram: 818180\n",
      "CPU times: user 4min 12s, sys: 2.81 s, total: 4min 15s\n",
      "Wall time: 4min 15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "create_trigram_dict(\"/Users/K-Lo/Desktop/big.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first_of_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# last_of_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# last_2counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# last_of_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# last_3counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# last_of_three[\"there\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \"here and\" in last_of_three[\"there\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \"here and\" in last_of_three[\"their\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_3counts[\"here and there\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \"and\" in last_of_two[\"there\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \"and\" in last_of_two[\"their\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_2counts[\"and there\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_2counts[\"and their\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def best_context(w1, w2, w_list, k):\n",
    "    '''determine most frequent trigram (greater than threshold k) for every w in w_list: (w1, w2, w)'''\n",
    "    # w_list comprises a list of tuples (w, (other info))\n",
    "    leading = w1 + \" \" + w2\n",
    "    \n",
    "    best_word = \"\"\n",
    "    trigram_found = False\n",
    "    best_tri_count = 0\n",
    "    best_bi_count = 0\n",
    "    \n",
    "    for item in w_list:\n",
    "        w = item[0]\n",
    "        if (leading in last_of_three[w]) and (last_3counts[leading + \" \" + w]>max(k, best_tri_count)):\n",
    "            best_tri_count = last_3counts[leading + \" \" + w]\n",
    "            best_word = w\n",
    "            trigram_found = True\n",
    "        elif (not trigram_found) and (w2 in last_of_two[w]) and (last_2counts[w2 + \" \" + w]>max(k, best_bi_count)):\n",
    "            # check bigrams only if no trigram candidates found\n",
    "            best_bi_count = last_2counts[w2 + \" \" + w]\n",
    "            best_word = w\n",
    "    \n",
    "    return best_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def correct_document_context(fname, context_threshold=5, num_word_suggestions=5000):\n",
    "    with open(fname) as file:\n",
    "        doc_word_count2 = 0\n",
    "        corrected_word_count = 0\n",
    "        unknown_word_count = 0\n",
    "        mismatches = 0\n",
    "        print \"Finding misspelled words in your document...\" \n",
    "        \n",
    "        word1 = \"\"\n",
    "        word2 = \"\"\n",
    "        first_two = True\n",
    "        \n",
    "        for i, line in enumerate(file):\n",
    "            doc_words2 = re.findall('[a-z]+', line.lower())  # separate by words by non-alphabetical characters      \n",
    "            for doc_word in doc_words2:\n",
    "                suggestion_w = None\n",
    "                suggestion_c = None\n",
    "                doc_word_count2 += 1\n",
    "                \n",
    "                if len(word1)==0:\n",
    "                    word1 = doc_word\n",
    "                elif len(word2)==0:\n",
    "                    word2 = doc_word\n",
    "                else:\n",
    "                    first_two = False\n",
    "                \n",
    "                # character level correction\n",
    "                list_suggestions_byword = get_suggestions(doc_word, silent=True)\n",
    "                if len(list_suggestions_byword)>num_word_suggestions:\n",
    "                    list_suggestions_byword = list_suggestions_byword[0:num_word_suggestions]\n",
    "                if len(list_suggestions_byword)>0:\n",
    "                    suggestion_w = list_suggestions_byword[0][0]  # string of most frequent word tuple\n",
    "                    \n",
    "                    # context correction on all potential suggestions\n",
    "                    # note if there are no suggestions, we do not perform context correction\n",
    "\n",
    "                    # current algorithm - choose the best trigram if count is over threshold\n",
    "                    # if none then choose best bigram (doc_word as last word) if count is over threshold\n",
    "                    # if none then use best character suggestion\n",
    "                    if not first_two:\n",
    "                        suggestion_c = best_context(word1, word2, list_suggestions_byword, context_threshold)\n",
    "                        # print suggestion_c\n",
    "                        if len(suggestion_c)==0:\n",
    "                            suggestion_c = suggestion_w\n",
    "                    else:\n",
    "                        suggestion_c = suggestion_w\n",
    "                \n",
    "                if suggestion_w is None:\n",
    "                    print \"In line %i, the word < %s > was not found (no suggested corrections)\" % (i, doc_word)\n",
    "                    unknown_word_count += 1\n",
    "                elif (suggestion_w!=doc_word) or (suggestion_c!=doc_word):\n",
    "                    print \"In line %i, (%s %s) %s: word level correction is < %s >, context correction is < %s >\" \\\n",
    "                              % (i, word1, word2, doc_word, suggestion_w, suggestion_c)\n",
    "                    corrected_word_count += 1\n",
    "                    if suggestion_w!=suggestion_c:\n",
    "                        mismatches += 1\n",
    "                                        \n",
    "                word1 = word2\n",
    "                word2 = doc_word\n",
    "        \n",
    "    print \"-----\"\n",
    "    print \"total words checked: %i\" % doc_word_count2\n",
    "    print \"total unknown words: %i\" % unknown_word_count\n",
    "    print \"total potential errors found: %i\" % corrected_word_count\n",
    "    print \"total mismatches (word level vs. context): %i\" % mismatches\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>For testing:</b><p>\n",
    "Provide text file to correct, and give all best word suggestions (word level & context level) for all known words.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test.txt\n",
    "\n",
    "#this is a test\n",
    "#this is a test\n",
    "#here is a test\n",
    "#this is ax test\n",
    "#this is za test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding misspelled words in your document...\n",
      "In line 0, (is a) test: word level correction is < test >, context correction is < very >\n",
      "In line 1, (is a) test: word level correction is < test >, context correction is < very >\n",
      "In line 2, (is a) test: word level correction is < test >, context correction is < very >\n",
      "In line 3, (this is) ax: word level correction is < ax >, context correction is < a >\n",
      "In line 4, (this is) za: word level correction is < a >, context correction is < a >\n",
      "-----\n",
      "total words checked: 20\n",
      "total unknown words: 0\n",
      "total potential errors found: 5\n",
      "total mismatches (word level vs. context): 4\n"
     ]
    }
   ],
   "source": [
    "correct_document_context(\"/Users/K-Lo/Desktop/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_3counts[\"is a very\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'is a test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-a6767cdf5c17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlast_3counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"is a test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'is a test'"
     ]
    }
   ],
   "source": [
    "last_3counts[\"is a test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'a test this'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-51f733e2b121>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlast_3counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"a test this\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'a test this'"
     ]
    }
   ],
   "source": [
    "last_3counts[\"a test this\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_3counts[\"a test tube\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding misspelled words in your document...\n",
      "In line 3, (ny di) taiths: word level correction is < faith >, context correction is < faith >\n",
      "In line 11, the word < oonipiittee > was not found (no suggested corrections)\n",
      "In line 11, (oonipiittee to) pay: word level correction is < pay >, context correction is < a >\n",
      "In line 11, (pay the) expenses: word level correction is < expenses >, context correction is < expense >\n",
      "In line 12, (expenses and) charges: word level correction is < charges >, context correction is < horses >\n",
      "In line 12, (preparing and) filing: word level correction is < filing >, context correction is < having >\n",
      "In line 12, (filing the) printed: word level correction is < printed >, context correction is < united >\n",
      "In line 13, (record and) brief: word level correction is < brief >, context correction is < are >\n",
      "In line 13, (julius and) t: word level correction is < t >, context correction is < the >\n",
      "In line 13, (and t) tj: word level correction is < to >, context correction is < it >\n",
      "In line 13, (tj f) d: word level correction is < d >, context correction is < and >\n",
      "In line 13, (f d) th: word level correction is < th >, context correction is < the >\n",
      "In line 13, (th t) n: word level correction is < n >, context correction is < know >\n",
      "In line 13, (t n) mnnff: word level correction is < snuff >, context correction is < snuff >\n",
      "In line 13, (mnnff t) gjpt: word level correction is < get >, context correction is < want >\n",
      "In line 13, (p t) t: word level correction is < t >, context correction is < want >\n",
      "In line 14, (t t) in: word level correction is < in >, context correction is < know >\n",
      "In line 14, (in the) supreme: word level correction is < supreme >, context correction is < extreme >\n",
      "In line 15, (have been) held: word level correction is < held >, context correction is < the >\n",
      "In line 15, (been held) bh: word level correction is < by >, context correction is < the >\n",
      "In line 15, (bh c) snc: word level correction is < sac >, context correction is < c >\n",
      "In line 15, (c snc) uth: word level correction is < th >, context correction is < th >\n",
      "In line 15, (c country) unuer: word level correction is < under >, context correction is < under >\n",
      "In line 16, (unuer the) auspices: word level correction is < auspices >, context correction is < spaces >\n",
      "In line 16, (the purpose) has: word level correction is < has >, context correction is < the >\n",
      "In line 16, (has been) to: word level correction is < to >, context correction is < lost >\n",
      "In line 17, (been to) raise: word level correction is < raise >, context correction is < his >\n",
      "In line 17, (for the) defense: word level correction is < defense >, context correction is < disease >\n",
      "In line 17, (of the) os: word level correction is < os >, context correction is < bone >\n",
      "In line 17, (os i) r: word level correction is < r >, context correction is < hear >\n",
      "In line 17, (g and) to: word level correction is < to >, context correction is < the >\n",
      "In line 17, (and to) rouse: word level correction is < rouse >, context correction is < you >\n",
      "In line 18, (sympathy for) them: word level correction is < them >, context correction is < the >\n",
      "In line 20, (for them) on: word level correction is < on >, context correction is < to >\n",
      "In line 20, (them on) march: word level correction is < march >, context correction is < which >\n",
      "In line 20, (national c) mthiitt: word level correction is < thirty >, context correction is < thirty >\n",
      "In line 20, (mthiitt to) secure: word level correction is < secure >, context correction is < see >\n",
      "In line 21, (secure justice) in: word level correction is < in >, context correction is < and >\n",
      "In line 21, (in the) r: word level correction is < r >, context correction is < form >\n",
      "In line 21, (r s) j: word level correction is < j >, context correction is < just >\n",
      "In line 21, (b f) cas: word level correction is < was >, context correction is < and >\n",
      "In line 21, (held a) meeting: word level correction is < meeting >, context correction is < feeling >\n",
      "In line 21, (a meeting) at: word level correction is < at >, context correction is < with >\n",
      "In line 22, (at the) pythian: word level correction is < scythian >, context correction is < thin >\n",
      "In line 22, (l west) th: word level correction is < th >, context correction is < the >\n",
      "In line 22, (th street) new: word level correction is < new >, context correction is < and >\n",
      "In line 23, (city which) was: word level correction is < was >, context correction is < is >\n",
      "In line 23, (which was) attended: word level correction is < attended >, context correction is < extended >\n",
      "In line 23, (oe to) people: word level correction is < people >, context correction is < prove >\n",
      "In line 25, (informant t) l: word level correction is < l >, context correction is < let >\n",
      "In line 25, (l of) unknown: word level correction is < unknown >, context correction is < union >\n",
      "In line 26, (reliability attended) the: word level correction is < the >, context correction is < with >\n",
      "In line 26, (attended the) above: word level correction is < above >, context correction is < whole >\n",
      "In line 26, (meeting and) stated: word level correction is < stated >, context correction is < said >\n",
      "In line 26, (that joseph) brainin: word level correction is < brain >, context correction is < brain >\n",
      "In line 27, (chairman and) opened: word level correction is < opened >, context correction is < one >\n",
      "In line 27, (opened the) meeting: word level correction is < meeting >, context correction is < morning >\n",
      "In line 27, (with greetings) jfl: word level correction is < of >, context correction is < of >\n",
      "In line 28, (jfl the) names: word level correction is < names >, context correction is < same >\n",
      "In line 28, (names of) ji: word level correction is < i >, context correction is < his >\n",
      "In line 28, (of ji) stice: word level correction is < stick >, context correction is < stick >\n",
      "In line 28, (ji stice) blaci: word level correction is < black >, context correction is < black >\n",
      "In line 28, (justice douglas) eug: word level correction is < dug >, context correction is < dug >\n",
      "In line 28, (eug n) debbs: word level correction is < debts >, context correction is < debts >\n",
      "In line 29, (debbs and) other: word level correction is < other >, context correction is < the >\n",
      "In line 29, (and other) great: word level correction is < great >, context correction is < guests >\n",
      "In line 29, (other great) a: word level correction is < a >, context correction is < and >\n",
      "In line 29, (great a) nericans: word level correction is < americans >, context correction is < americans >\n",
      "In line 29, (nericans to) whom: word level correction is < whom >, context correction is < the >\n",
      "In line 29, (liberty and) justice: word level correction is < justice >, context correction is < just >\n",
      "In line 29, (justice i) not: word level correction is < not >, context correction is < don >\n",
      "In line 30, (phrase b) ainin: word level correction is < again >, context correction is < again >\n",
      "In line 30, (that the) r: word level correction is < r >, context correction is < war >\n",
      "In line 30, (the r) se: word level correction is < se >, context correction is < s >\n",
      "In line 30, (r se) ergs: word level correction is < eggs >, context correction is < eggs >\n",
      "In line 31, (convicted on) trumped: word level correction is < trumpet >, context correction is < trumpet >\n",
      "In line 31, (evidence and) that: word level correction is < that >, context correction is < the >\n",
      "In line 31, (that the) main: word level correction is < main >, context correction is < man >\n",
      "In line 32, (aim of) their: word level correction is < their >, context correction is < the >\n",
      "In line 32, (their conviction) was: word level correction is < was >, context correction is < that >\n",
      "In line 32, (conviction was) to: word level correction is < to >, context correction is < the >\n",
      "In line 32, (was to) warn: word level correction is < warn >, context correction is < have >\n",
      "In line 32, (warn the) erican: word level correction is < american >, context correction is < american >\n",
      "In line 33, (erican people) that: word level correction is < that >, context correction is < who >\n",
      "In line 33, (people that) all: word level correction is < all >, context correction is < had >\n",
      "In line 33, (holders of) unorthodox: word level correction is < orthodox >, context correction is < orthodox >\n",
      "In line 33, (unorthodox views) are: word level correction is < are >, context correction is < and >\n",
      "In line 33, (views are) a: word level correction is < a >, context correction is < all >\n",
      "In line 33, (are a) nenance: word level correction is < penance >, context correction is < chance >\n",
      "In line 33, (nenance to) thg: word level correction is < the >, context correction is < the >\n",
      "In line 34, (citizens he) claimed: word level correction is < claimed >, context correction is < came >\n",
      "In line 34, (that the) conviction: word level correction is < conviction >, context correction is < condition >\n",
      "In line 34, (of the) r: word level correction is < r >, context correction is < room >\n",
      "In line 34, (the r) sln: word level correction is < son >, context correction is < s >\n",
      "In line 34, (r sln) rgs: word level correction is < rags >, context correction is < rags >\n",
      "In line 35, (rgs and) their: word level correction is < their >, context correction is < the >\n",
      "In line 35, (sentence too) death: word level correction is < death >, context correction is < late >\n",
      "In line 35, (too death) is: word level correction is < is >, context correction is < in >\n",
      "In line 35, (death is) an: word level correction is < an >, context correction is < a >\n",
      "In line 35, (is an) eternal: word level correction is < eternal >, context correction is < interval >\n",
      "In line 35, (eternal shame) on: word level correction is < on >, context correction is < and >\n",
      "In line 38, (american justice) williaij: word level correction is < william >, context correction is < william >\n",
      "In line 38, (justice williaij) eu: word level correction is < e >, context correction is < e >\n",
      "In line 38, (eu i) n: word level correction is < n >, context correction is < don >\n",
      "In line 39, (weekly in) new: word level correction is < new >, context correction is < the >\n",
      "In line 40, (next spoke) and: word level correction is < and >, context correction is < in >\n",
      "In line 40, (spoke and) said: word level correction is < said >, context correction is < a >\n",
      "In line 40, (that the) fcsf: word level correction is < ff >, context correction is < first >\n",
      "In line 40, (the fcsf) ber: word level correction is < be >, context correction is < be >\n",
      "In line 40, (ber and) s: word level correction is < s >, context correction is < his >\n",
      "In line 40, (and s) b: word level correction is < b >, context correction is < back >\n",
      "In line 40, (b ll) were: word level correction is < were >, context correction is < be >\n",
      "In line 41, (espionage but) f: word level correction is < f >, context correction is < if >\n",
      "In line 41, (but f) r: word level correction is < r >, context correction is < or >\n",
      "In line 42, (r political) unorthodoxy: word level correction is < orthodox >, context correction is < orthodox >\n",
      "In line 42, (unorthodoxy he) claimed: word level correction is < claimed >, context correction is < came >\n",
      "In line 42, (he claimed) thpt: word level correction is < that >, context correction is < that >\n",
      "In line 42, (thpt the) r: word level correction is < r >, context correction is < room >\n",
      "In line 42, the word < senbrnrgs > was not found (no suggested corrections)\n",
      "In line 43, (of the) cold: word level correction is < cold >, context correction is < bone >\n",
      "In line 43, (the cold) war: word level correction is < war >, context correction is < and >\n",
      "In line 43, (cold war) of: word level correction is < of >, context correction is < on >\n",
      "In line 43, (of the) forces: word level correction is < forces >, context correction is < bones >\n",
      "In line 43, (forces which) are: word level correction is < are >, context correction is < he >\n",
      "In line 43, (which are) trying: word level correction is < trying >, context correction is < going >\n",
      "In line 43, (trying to) plunge: word level correction is < plunge >, context correction is < prince >\n",
      "In line 44, (humanity into) chaos: word level correction is < chaos >, context correction is < his >\n",
      "In line 44, (chaos and) fascism: word level correction is < fascia >, context correction is < fascia >\n",
      "In line 62, (fascism ny) loo: word level correction is < look >, context correction is < look >\n",
      "In line 65, (loo h) ththn: word level correction is < then >, context correction is < then >\n",
      "In line 65, (h ththn) scbell: word level correction is < bell >, context correction is < bell >\n",
      "In line 65, (scbell the) i: word level correction is < i >, context correction is < skin >\n",
      "In line 65, (the i) ife: word level correction is < if >, context correction is < have >\n",
      "In line 65, (ife of) i: word level correction is < i >, context correction is < his >\n",
      "In line 65, (of i) yktcn: word level correction is < skin >, context correction is < often >\n",
      "In line 65, (yktcn sob) thl: word level correction is < the >, context correction is < the >\n",
      "In line 66, (next addressed) thi: word level correction is < the >, context correction is < to >\n",
      "In line 66, (nd stated) th: word level correction is < th >, context correction is < that >\n",
      "In line 66, (th t) her: word level correction is < her >, context correction is < be >\n",
      "In line 67, (and the) os: word level correction is < os >, context correction is < old >\n",
      "In line 67, (f c) are: word level correction is < are >, context correction is < est >\n",
      "In line 67, (innocent and) that: word level correction is < that >, context correction is < the >\n",
      "In line 67, (and that) they: word level correction is < they >, context correction is < the >\n",
      "In line 67, (that they) are: word level correction is < are >, context correction is < were >\n",
      "In line 67, (victims of) red: word level correction is < red >, context correction is < the >\n",
      "In line 68, (hysteria she) saij: word level correction is < said >, context correction is < had >\n",
      "In line 68, (saij that) as: word level correction is < as >, context correction is < is >\n",
      "In line 68, (that as) soon: word level correction is < soon >, context correction is < to >\n",
      "In line 68, (soon as) it: word level correction is < it >, context correction is < the >\n",
      "In line 68, (as it) was: word level correction is < was >, context correction is < is >\n",
      "In line 68, (was decided) that: word level correction is < that >, context correction is < to >\n",
      "In line 69, (that the) defendants: word level correction is < defendant >, context correction is < defendant >\n",
      "In line 69, (defendants were) cornr: word level correction is < corner >, context correction is < on >\n",
      "In line 69, (were cornr) nists: word level correction is < fists >, context correction is < fists >\n",
      "In line 69, (nists the) trial: word level correction is < trial >, context correction is < great >\n",
      "In line 69, (became a) massacre: word level correction is < massacre >, context correction is < passage >\n",
      "In line 70, (massacre she) appealed: word level correction is < appealed >, context correction is < repeated >\n",
      "In line 70, (the people) before: word level correction is < before >, context correction is < were >\n",
      "In line 70, (people before) we: word level correction is < we >, context correction is < the >\n",
      "In line 70, (before we) were: word level correction is < were >, context correction is < have >\n",
      "In line 70, (we were) helping: word level correction is < helping >, context correction is < being >\n",
      "In line 70, (helping you) in: word level correction is < in >, context correction is < know >\n",
      "In line 71, (in the) fight: word level correction is < fight >, context correction is < first >\n",
      "In line 71, (for a) better: word level correction is < better >, context correction is < letter >\n",
      "In line 71, (better world) flow: word level correction is < flow >, context correction is < of >\n",
      "In line 71, (world flow) you: word level correction is < you >, context correction is < of >\n",
      "In line 71, (you must) help: word level correction is < help >, context correction is < be >\n",
      "In line 71, (must help) us: word level correction is < us >, context correction is < you >\n",
      "In line 71, (us to) free: word level correction is < free >, context correction is < the >\n",
      "In line 72, (free my) husband: word level correction is < husband >, context correction is < hand >\n",
      "In line 72, (and the) ro: word level correction is < to >, context correction is < old >\n",
      "In line 74, (bl g) ath: word level correction is < at >, context correction is < at >\n",
      "In line 74, (ath t) k: word level correction is < k >, context correction is < know >\n",
      "In line 74, (collection speech) in: word level correction is < in >, context correction is < and >\n",
      "In line 74, (speech in) which: word level correction is < which >, context correction is < his >\n",
      "In line 75, (in which) he: word level correction is < he >, context correction is < the >\n",
      "In line 75, (which he) st: word level correction is < st >, context correction is < was >\n",
      "In line 75, (st ed) tti: word level correction is < ti >, context correction is < ti >\n",
      "In line 75, (tti t) the: word level correction is < the >, context correction is < be >\n",
      "In line 75, (t the) r: word level correction is < r >, context correction is < room >\n",
      "In line 75, (r s) n: word level correction is < n >, context correction is < not >\n",
      "In line 75, (s n) rg: word level correction is < re >, context correction is < re >\n",
      "In line 75, (rg were) being: word level correction is < being >, context correction is < in >\n",
      "In line 75, (were being) acrific: word level correction is < pacific >, context correction is < pacific >\n",
      "In line 76, (on the) altar: word level correction is < altar >, context correction is < floor >\n",
      "In line 76, (altar of) war: word level correction is < war >, context correction is < a >\n",
      "In line 76, (of war) he: word level correction is < he >, context correction is < the >\n",
      "In line 76, (war he) stated: word level correction is < stated >, context correction is < said >\n",
      "In line 76, (we must) stop: word level correction is < stop >, context correction is < not >\n",
      "In line 77, (killer in) korea: word level correction is < more >, context correction is < one >\n",
      "In line 77, (korea by) stepping: word level correction is < stepping >, context correction is < sending >\n",
      "In line 78, (of the) ro: word level correction is < to >, context correction is < bone >\n",
      "In line 78, (g they) face: word level correction is < face >, context correction is < were >\n",
      "In line 78, (they face) doatli: word level correction is < death >, context correction is < death >\n",
      "In line 78, (doatli because) they: word level correction is < they >, context correction is < he >\n",
      "In line 78, (because they) fought: word level correction is < fought >, context correction is < might >\n",
      "In line 78, (fought for) u: word level correction is < u >, context correction is < you >\n",
      "In line 79, (we must) fight: word level correction is < fight >, context correction is < get >\n",
      "In line 79, (fight for) them: word level correction is < them >, context correction is < the >\n",
      "In line 81, (for them) ith: word level correction is < it >, context correction is < to >\n",
      "In line 81, (them ith) ry: word level correction is < by >, context correction is < by >\n",
      "In line 81, (ry van) kl: word level correction is < ll >, context correction is < ll >\n",
      "In line 81, (van kl) ech: word level correction is < each >, context correction is < each >\n",
      "In line 81, (next spoke) and: word level correction is < and >, context correction is < in >\n",
      "In line 81, (spoke and) stated: word level correction is < stated >, context correction is < said >\n",
      "In line 81, (stated that) she: word level correction is < she >, context correction is < the >\n",
      "In line 82, (that she) made: word level correction is < made >, context correction is < was >\n",
      "In line 82, (made a) th: word level correction is < th >, context correction is < third >\n",
      "In line 82, (a th) rb: word level correction is < re >, context correction is < re >\n",
      "In line 82, the word < ghmhvestigat > was not found (no suggested corrections)\n",
      "In line 82, (of the) rd: word level correction is < rd >, context correction is < room >\n",
      "In line 82, (the rd) nb: word level correction is < no >, context correction is < no >\n",
      "In line 82, (rd nb) rg: word level correction is < re >, context correction is < re >\n",
      "In line 82, (rg case) and: word level correction is < and >, context correction is < in >\n",
      "In line 83, (case and) that: word level correction is < that >, context correction is < the >\n",
      "In line 83, (and that) she: word level correction is < she >, context correction is < the >\n",
      "In line 83, (that she) came: word level correction is < came >, context correction is < was >\n",
      "In line 83, (that the) rosenbt: word level correction is < rodent >, context correction is < moment >\n",
      "In line 83, (the rosenbt) rgs: word level correction is < rags >, context correction is < rags >\n",
      "In line 84, (were condemned) to: word level correction is < to >, context correction is < the >\n",
      "In line 84, (condemned to) death: word level correction is < death >, context correction is < get >\n",
      "In line 84, (to death) not: word level correction is < not >, context correction is < of >\n",
      "In line 84, (not because) they: word level correction is < they >, context correction is < he >\n",
      "In line 84, (because they) coriritted: word level correction is < committed >, context correction is < committed >\n",
      "In line 85, (but because) they: word level correction is < they >, context correction is < he >\n",
      "In line 85, (belonged to) those: word level correction is < those >, context correction is < the >\n",
      "In line 85, (those elements) who: word level correction is < who >, context correction is < of >\n",
      "In line 85, (elements who) are: word level correction is < are >, context correction is < had >\n",
      "In line 86, (who are) fighti: word level correction is < fight >, context correction is < fight >\n",
      "In line 86, (g for) progress: word level correction is < progress >, context correction is < princess >\n",
      "In line 86, (and a) better: word level correction is < better >, context correction is < letter >\n",
      "In line 88, (better world) bths: word level correction is < baths >, context correction is < to >\n",
      "In line 88, (bths i) j: word level correction is < j >, context correction is < just >\n",
      "In line 88, (i j) tchf: word level correction is < the >, context correction is < c >\n",
      "In line 88, (next spoke) and: word level correction is < and >, context correction is < in >\n",
      "In line 88, (spoke and) told: word level correction is < told >, context correction is < the >\n",
      "In line 88, (and told) the: word level correction is < the >, context correction is < him >\n",
      "In line 88, (told the) people: word level correction is < people >, context correction is < whole >\n",
      "In line 89, (the people) to: word level correction is < to >, context correction is < of >\n",
      "In line 89, (people to) go: word level correction is < go >, context correction is < do >\n",
      "In line 89, (to go) back: word level correction is < back >, context correction is < and >\n",
      "In line 89, (back and) tell: word level correction is < tell >, context correction is < the >\n",
      "In line 89, (and tell) the: word level correction is < the >, context correction is < me >\n",
      "In line 89, (tell the) people: word level correction is < people >, context correction is < whole >\n",
      "In line 89, (people in) their: word level correction is < their >, context correction is < the >\n",
      "In line 90, (neighborhoods what) was: word level correction is < was >, context correction is < is >\n",
      "In line 90, (was said) at: word level correction is < at >, context correction is < to >\n",
      "In line 90, (at the) meeting: word level correction is < meeting >, context correction is < opening >\n",
      "In line 90, (the meeting) so: word level correction is < so >, context correction is < of >\n",
      "In line 90, (meeting so) they: word level correction is < they >, context correction is < that >\n",
      "In line 90, (they could) learn: word level correction is < learn >, context correction is < hear >\n",
      "In line 90, (learn the) truth: word level correction is < truth >, context correction is < south >\n",
      "In line 91, (about the) ro: word level correction is < to >, context correction is < war >\n",
      "In line 91, (the ro) ijb: word level correction is < in >, context correction is < in >\n",
      "In line 91, (g c) se: word level correction is < se >, context correction is < est >\n",
      "In line 91, (se and) fight: word level correction is < fight >, context correction is < with >\n",
      "In line 91, (fight for) their: word level correction is < their >, context correction is < the >\n",
      "In line 91, (for their) lives: word level correction is < lives >, context correction is < faces >\n",
      "In line 92, (lives and) freedom: word level correction is < freedom >, context correction is < from >\n",
      "In line 92, (and freedom) she: word level correction is < she >, context correction is < that >\n",
      "In line 92, (freedom she) read: word level correction is < read >, context correction is < had >\n",
      "In line 92, (she read) a: word level correction is < a >, context correction is < and >\n",
      "In line 92, (read a) telegrnm: word level correction is < telegram >, context correction is < telegram >\n",
      "In line 92, (telegrnm from) jillia: word level correction is < william >, context correction is < william >\n",
      "In line 92, (jillia i) patt: word level correction is < part >, context correction is < have >\n",
      "In line 92, (i patt) rson: word level correction is < son >, context correction is < son >\n",
      "In line 93, (national executive) ecretdry: word level correction is < secretary >, context correction is < secretary >\n",
      "In line 94, (rights congress) an: word level correction is < an >, context correction is < in >\n",
      "In line 94, (attorney general) as: word level correction is < as >, context correction is < and >\n",
      "In line 94, (general as) coming: word level correction is < coming >, context correction is < long >\n",
      "In line 95, (within the) purview: word level correction is < purves >, context correction is < view >\n",
      "In line 95, (of executive) rder: word level correction is < order >, context correction is < order >\n",
      "In line 95, (rder in) which: word level correction is < which >, context correction is < his >\n",
      "In line 95, (in which) he: word level correction is < he >, context correction is < the >\n",
      "In line 96, (which he) promised: word level correction is < promised >, context correction is < raised >\n",
      "In line 96, (he promised) the: word level correction is < the >, context correction is < to >\n",
      "In line 96, (promised the) aid: word level correction is < aid >, context correction is < same >\n",
      "In line 96, (the aid) and: word level correction is < and >, context correction is < in >\n",
      "In line 97, (in the) fight: word level correction is < fight >, context correction is < first >\n",
      "In line 97, (for justice) in: word level correction is < in >, context correction is < and >\n",
      "In line 97, (in the) i: word level correction is < i >, context correction is < skin >\n",
      "In line 97, (v berg) case: word level correction is < case >, context correction is < and >\n",
      "In line 99, (b z) gor: word level correction is < for >, context correction is < for >\n",
      "In line 99, (z gor) dthethg: word level correction is < teeth >, context correction is < teeth >\n",
      "In line 99, (dthethg cor) ared: word level correction is < are >, context correction is < are >\n",
      "In line 99, (ared the) ro: word level correction is < to >, context correction is < old >\n",
      "In line 99, (the ro) enb: word level correction is < end >, context correction is < end >\n",
      "In line 99, (ro enb) rg: word level correction is < re >, context correction is < re >\n",
      "In line 100, (rg case) to: word level correction is < to >, context correction is < of >\n",
      "In line 100, (to the) case: word level correction is < case >, context correction is < house >\n",
      "In line 100, (case of) sacc: word level correction is < sac >, context correction is < a >\n",
      "In line 100, (sacc and) vthnz: word level correction is < the >, context correction is < the >\n",
      "In line 100, (and the) dri: word level correction is < dry >, context correction is < old >\n",
      "In line 100, (the dri) yfu: word level correction is < you >, context correction is < you >\n",
      "In line 100, (yfu s) case: word level correction is < case >, context correction is < face >\n",
      "In line 101, (s case) ile: word level correction is < ill >, context correction is < the >\n",
      "In line 101, (ile stated) the: word level correction is < the >, context correction is < that >\n",
      "In line 101, (stated the) way: word level correction is < way >, context correction is < same >\n",
      "In line 101, (the way) this: word level correction is < this >, context correction is < to >\n",
      "In line 101, (way this) case: word level correction is < case >, context correction is < is >\n",
      "In line 101, (this case) was: word level correction is < was >, context correction is < and >\n",
      "In line 101, (case was) conducted: word level correction is < conducted >, context correction is < connected >\n",
      "In line 101, (conducted the) rosi: word level correction is < rose >, context correction is < old >\n",
      "In line 101, (rosi t) rg: word level correction is < re >, context correction is < go >\n",
      "In line 102, (could not) get: word level correction is < get >, context correction is < be >\n",
      "In line 102, (not get) a: word level correction is < a >, context correction is < away >\n",
      "In line 102, (get a) fnir: word level correction is < fair >, context correction is < few >\n",
      "In line 102, (fnir trial) jhy: word level correction is < why >, context correction is < by >\n",
      "In line 102, (jhy is) it: word level correction is < it >, context correction is < the >\n",
      "In line 102, (is it) that: word level correction is < that >, context correction is < not >\n",
      "In line 102, (that the) azi: word level correction is < ami >, context correction is < man >\n",
      "In line 103, (azi and) fascist: word level correction is < fascia >, context correction is < fast >\n",
      "In line 103, (spies were) net: word level correction is < net >, context correction is < the >\n",
      "In line 103, (given a) death: word level correction is < death >, context correction is < great >\n",
      "In line 103, (sentence in) time: word level correction is < time >, context correction is < the >\n",
      "In line 103, (in time) of: word level correction is < of >, context correction is < to >\n",
      "In line 104, (time of) war: word level correction is < war >, context correction is < a >\n",
      "In line 104, (and the) o: word level correction is < o >, context correction is < old >\n",
      "In line 104, (the o) nb: word level correction is < no >, context correction is < no >\n",
      "In line 104, (given a) death: word level correction is < death >, context correction is < great >\n",
      "In line 104, (sentence in) time: word level correction is < time >, context correction is < the >\n",
      "In line 105, (in time) of: word level correction is < of >, context correction is < to >\n",
      "In line 105, (time of) peace: word level correction is < peace >, context correction is < state >\n",
      "In line 105, (of peace) is: word level correction is < is >, context correction is < with >\n",
      "In line 105, (peace is) it: word level correction is < it >, context correction is < the >\n",
      "In line 105, (is it) because: word level correction is < because >, context correction is < becomes >\n",
      "In line 105, (it because) they: word level correction is < they >, context correction is < he >\n",
      "In line 105, (because they) are: word level correction is < are >, context correction is < were >\n",
      "In line 105, (they are) jews: word level correction is < jews >, context correction is < met >\n",
      "-----\n",
      "total words checked: 700\n",
      "total unknown words: 3\n",
      "total potential errors found: 326\n",
      "total mismatches (word level vs. context): 267\n"
     ]
    }
   ],
   "source": [
    "correct_document_context(\"/Users/K-Lo/Desktop/OCRsample.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding misspelled words in your document...\n",
      "In line 0, (started my) schooling: word level correction is < choosing >, context correction is < choosing >\n",
      "In line 0, (the majority) did: word level correction is < did >, context correction is < in >\n",
      "In line 0, (majority did) in: word level correction is < in >, context correction is < not >\n",
      "In line 0, (in my) area: word level correction is < area >, context correction is < dear >\n",
      "In line 0, (my area) at: word level correction is < at >, context correction is < and >\n",
      "In line 0, (at the) local: word level correction is < local >, context correction is < road >\n",
      "In line 0, (the local) primarry: word level correction is < primary >, context correction is < primary >\n",
      "In line 0, (school i) then: word level correction is < then >, context correction is < don >\n",
      "In line 0, (i then) went: word level correction is < went >, context correction is < he >\n",
      "In line 0, (to the) local: word level correction is < local >, context correction is < law >\n",
      "In line 0, (the local) secondarry: word level correction is < secondary >, context correction is < secondary >\n",
      "In line 0, (school and) recieved: word level correction is < received >, context correction is < received >\n",
      "In line 0, (grades in) english: word level correction is < english >, context correction is < england >\n",
      "In line 0, (in english) maths: word level correction is < baths >, context correction is < baths >\n",
      "In line 0, (english maths) phisics: word level correction is < physics >, context correction is < physics >\n",
      "In line 0, (geography art) graphical: word level correction is < graphics >, context correction is < graphics >\n",
      "In line 0, (art graphical) comunication: word level correction is < communication >, context correction is < communication >\n",
      "In line 0, (philosophy of) religeon: word level correction is < religion >, context correction is < relief >\n",
      "In line 0, (religeon i) ll: word level correction is < ll >, context correction is < shall >\n",
      "In line 0, (i ll) not: word level correction is < not >, context correction is < go >\n",
      "In line 0, (ll not) bore: word level correction is < bore >, context correction is < to >\n",
      "In line 0, (bore you) with: word level correction is < with >, context correction is < will >\n",
      "In line 0, (with the) a: word level correction is < a >, context correction is < same >\n",
      "In line 0, (the a) levels: word level correction is < levels >, context correction is < severe >\n",
      "In line 0, (levels and) above: word level correction is < above >, context correction is < more >\n",
      "In line 1, (notice the) ambigous: word level correction is < ambiguous >, context correction is < ambiguous >\n",
      "In line 1, (qualification above) it: word level correction is < it >, context correction is < the >\n",
      "In line 1, (above it) was: word level correction is < was >, context correction is < is >\n",
      "In line 1, (it was) in: word level correction is < in >, context correction is < not >\n",
      "In line 1, (was in) truth: word level correction is < truth >, context correction is < such >\n",
      "In line 1, (in truth) a: word level correction is < a >, context correction is < and >\n",
      "In line 1, (truth a) cource: word level correction is < course >, context correction is < more >\n",
      "In line 1, (dedicated to) reading: word level correction is < reading >, context correction is < remain >\n",
      "In line 1, (to reading) lord: word level correction is < lord >, context correction is < of >\n",
      "In line 1, (of the) flies: word level correction is < flies >, context correction is < limb >\n",
      "In line 1, (flies and) other: word level correction is < other >, context correction is < the >\n",
      "In line 1, (and other) gems: word level correction is < gems >, context correction is < forms >\n",
      "In line 1, (and a) weak: word level correction is < weak >, context correction is < few >\n",
      "In line 1, (a weak) atempt: word level correction is < attempt >, context correction is < attempt >\n",
      "In line 1, (atempt at) getting: word level correction is < getting >, context correction is < being >\n",
      "In line 1, (at getting) us: word level correction is < us >, context correction is < up >\n",
      "In line 1, (us to) commprehend: word level correction is < comprehend >, context correction is < comprehend >\n",
      "In line 1, (commprehend them) luckilly: word level correction is < luckily >, context correction is < luckily >\n",
      "In line 1, (luckilly my) middle: word level correction is < middle >, context correction is < mind >\n",
      "In line 1, (my middle) class: word level correction is < class >, context correction is < coats >\n",
      "In line 1, (upbringing gave) me: word level correction is < me >, context correction is < him >\n",
      "In line 1, (gave me) a: word level correction is < a >, context correction is < and >\n",
      "In line 1, (me a) head: word level correction is < head >, context correction is < man >\n",
      "In line 1, (a head) start: word level correction is < start >, context correction is < that >\n",
      "In line 1, (head start) as: word level correction is < as >, context correction is < at >\n",
      "In line 1, (start as) i: word level correction is < i >, context correction is < if >\n",
      "In line 1, (as i) was: word level correction is < was >, context correction is < have >\n",
      "In line 1, (was already) aquainted: word level correction is < acquainted >, context correction is < acquainted >\n",
      "In line 1, (aquainted with) that: word level correction is < that >, context correction is < the >\n",
      "In line 1, (with that) sort: word level correction is < sort >, context correction is < of >\n",
      "In line 1, (sort of) langauge: word level correction is < language >, context correction is < language >\n",
      "In line 1, (langauge these) books: word level correction is < books >, context correction is < words >\n",
      "In line 1, (these books) used: word level correction is < used >, context correction is < and >\n",
      "In line 1, (books used) and: word level correction is < and >, context correction is < in >\n",
      "In line 1, (used and) not: word level correction is < not >, context correction is < the >\n",
      "In line 1, (and not) just: word level correction is < just >, context correction is < yet >\n",
      "In line 1, (not just) the: word level correction is < the >, context correction is < then >\n",
      "In line 1, (just the) peter: word level correction is < peter >, context correction is < other >\n",
      "In line 1, (peter and) jane: word level correction is < jane >, context correction is < the >\n",
      "In line 1, (books and) had: word level correction is < had >, context correction is < the >\n",
      "In line 1, (and had) read: word level correction is < read >, context correction is < a >\n",
      "In line 1, (had read) simillar: word level correction is < similar >, context correction is < similar >\n",
      "In line 1, (books before) i: word level correction is < i >, context correction is < him >\n",
      "In line 1, (before i) will: word level correction is < will >, context correction is < was >\n",
      "In line 1, (i will) never: word level correction is < never >, context correction is < give >\n",
      "In line 1, (never be) able: word level correction is < able >, context correction is < a >\n",
      "In line 1, (able to) put: word level correction is < put >, context correction is < the >\n",
      "In line 1, (to put) that: word level correction is < that >, context correction is < it >\n",
      "In line 1, (put that) paticular: word level correction is < particular >, context correction is < particular >\n",
      "In line 1, (paticular course) down: word level correction is < down >, context correction is < of >\n",
      "In line 1, (course down) as: word level correction is < as >, context correction is < and >\n",
      "In line 1, (much as) i: word level correction is < i >, context correction is < if >\n",
      "In line 1, (as i) desire: word level correction is < desire >, context correction is < were >\n",
      "In line 1, (desire to) because: word level correction is < because >, context correction is < become >\n",
      "In line 1, (to because) for: word level correction is < for >, context correction is < of >\n",
      "In line 1, (because for) all: word level correction is < all >, context correction is < a >\n",
      "In line 1, (for all) its: word level correction is < its >, context correction is < the >\n",
      "In line 1, (all its) faults: word level correction is < faults >, context correction is < walls >\n",
      "In line 1, (it introduced) me: word level correction is < me >, context correction is < him >\n",
      "In line 1, the word < steinbeck > was not found (no suggested corrections)\n",
      "In line 1, (to steinbeck) malkovich: word level correction is < pavlovich >, context correction is < pavlovich >\n",
      "In line 1, (and the) wonders: word level correction is < wonders >, context correction is < others >\n",
      "In line 1, (wonders of) lenny: word level correction is < penny >, context correction is < any >\n",
      "In line 1, (mice and) pockets: word level correction is < pockets >, context correction is < locked >\n",
      "In line 2, (never included) one: word level correction is < one >, context correction is < in >\n",
      "In line 2, (included one) iota: word level correction is < iota >, context correction is < of >\n",
      "In line 2, (truss points) out: word level correction is < out >, context correction is < of >\n",
      "In line 2, (points out) in: word level correction is < in >, context correction is < his >\n",
      "In line 2, (out in) eats: word level correction is < eats >, context correction is < a >\n",
      "In line 2, (shoots and) leaves: word level correction is < leaves >, context correction is < even >\n",
      "In line 2, (leaves that) many: word level correction is < many >, context correction is < they >\n",
      "In line 2, (many people) were: word level correction is < were >, context correction is < who >\n",
      "In line 2, (from the) rigours: word level correction is < rigors >, context correction is < rights >\n",
      "In line 2, (rigours of) learning: word level correction is < learning >, context correction is < healing >\n",
      "In line 2, (grammar during) their: word level correction is < their >, context correction is < the >\n",
      "In line 2, (during their) schooling: word level correction is < choosing >, context correction is < choosing >\n",
      "In line 2, (over the) last: word level correction is < last >, context correction is < same >\n",
      "In line 2, (the last) or: word level correction is < or >, context correction is < of >\n",
      "In line 2, (last or) so: word level correction is < so >, context correction is < of >\n",
      "In line 2, (or so) years: word level correction is < years >, context correction is < as >\n",
      "In line 2, (years because) the: word level correction is < the >, context correction is < he >\n",
      "In line 2, (the majority) or: word level correction is < or >, context correction is < of >\n",
      "In line 2, (makers decided) one: word level correction is < one >, context correction is < to >\n",
      "In line 2, (decided one) day: word level correction is < day >, context correction is < and >\n",
      "In line 2, (one day) that: word level correction is < that >, context correction is < the >\n",
      "In line 2, (day that) it: word level correction is < it >, context correction is < the >\n",
      "In line 2, (imagination and) expresion: word level correction is < expression >, context correction is < expressed >\n",
      "In line 2, (expresion so) what: word level correction is < what >, context correction is < that >\n",
      "In line 2, (so what) i: word level correction is < i >, context correction is < is >\n",
      "In line 2, (what i) ask: word level correction is < ask >, context correction is < have >\n",
      "In line 2, (happened to) all: word level correction is < all >, context correction is < a >\n",
      "In line 2, (to all) those: word level correction is < those >, context correction is < the >\n",
      "In line 2, (all those) expresive: word level correction is < expressive >, context correction is < expressive >\n",
      "In line 2, (imaginative people) before: word level correction is < before >, context correction is < were >\n",
      "In line 2, (before the) ruling: word level correction is < ruling >, context correction is < king >\n",
      "In line 4, the word < usingenglish > was not found (no suggested corrections)\n",
      "In line 4, (com files) pdf: word level correction is < of >, context correction is < of >\n",
      "In line 4, (pdf spelling) pdf: word level correction is < of >, context correction is < of >\n",
      "-----\n",
      "total words checked: 234\n",
      "total unknown words: 2\n",
      "total potential errors found: 121\n",
      "total mismatches (word level vs. context): 100\n"
     ]
    }
   ],
   "source": [
    "correct_document_context(\"/Users/K-Lo/Desktop/usingengsample.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding misspelled words in your document...\n",
      "In line 0, (started my) schooling: word level correction is < choosing >, context correction is < choosing >\n",
      "In line 0, (the local) primarry: word level correction is < primary >, context correction is < primary >\n",
      "In line 0, (the local) secondarry: word level correction is < secondary >, context correction is < secondary >\n",
      "In line 0, (school and) recieved: word level correction is < received >, context correction is < received >\n",
      "In line 0, (in english) maths: word level correction is < baths >, context correction is < baths >\n",
      "In line 0, (english maths) phisics: word level correction is < physics >, context correction is < physics >\n",
      "In line 0, (geography art) graphical: word level correction is < graphics >, context correction is < graphics >\n",
      "In line 0, (art graphical) comunication: word level correction is < communication >, context correction is < communication >\n",
      "In line 0, (philosophy of) religeon: word level correction is < religion >, context correction is < religion >\n",
      "In line 1, (notice the) ambigous: word level correction is < ambiguous >, context correction is < ambiguous >\n",
      "In line 1, (truth a) cource: word level correction is < course >, context correction is < course >\n",
      "In line 1, (and a) weak: word level correction is < weak >, context correction is < week >\n",
      "In line 1, (a weak) atempt: word level correction is < attempt >, context correction is < attempt >\n",
      "In line 1, (us to) commprehend: word level correction is < comprehend >, context correction is < comprehend >\n",
      "In line 1, (commprehend them) luckilly: word level correction is < luckily >, context correction is < luckily >\n",
      "In line 1, (start as) i: word level correction is < i >, context correction is < if >\n",
      "In line 1, (was already) aquainted: word level correction is < acquainted >, context correction is < acquainted >\n",
      "In line 1, (sort of) langauge: word level correction is < language >, context correction is < language >\n",
      "In line 1, (had read) simillar: word level correction is < similar >, context correction is < similar >\n",
      "In line 1, (put that) paticular: word level correction is < particular >, context correction is < particular >\n",
      "In line 1, (much as) i: word level correction is < i >, context correction is < if >\n",
      "In line 1, (desire to) because: word level correction is < because >, context correction is < become >\n",
      "In line 1, the word < steinbeck > was not found (no suggested corrections)\n",
      "In line 1, (to steinbeck) malkovich: word level correction is < pavlovich >, context correction is < pavlovich >\n",
      "In line 1, (wonders of) lenny: word level correction is < penny >, context correction is < penny >\n",
      "In line 2, (from the) rigours: word level correction is < rigors >, context correction is < rigors >\n",
      "In line 2, (grammar during) their: word level correction is < their >, context correction is < the >\n",
      "In line 2, (during their) schooling: word level correction is < choosing >, context correction is < choosing >\n",
      "In line 2, (last or) so: word level correction is < so >, context correction is < to >\n",
      "In line 2, (years because) the: word level correction is < the >, context correction is < he >\n",
      "In line 2, (the majority) or: word level correction is < or >, context correction is < of >\n",
      "In line 2, (imagination and) expresion: word level correction is < expression >, context correction is < expression >\n",
      "In line 2, (expresion so) what: word level correction is < what >, context correction is < that >\n",
      "In line 2, (so what) i: word level correction is < i >, context correction is < is >\n",
      "In line 2, (to all) those: word level correction is < those >, context correction is < the >\n",
      "In line 2, (all those) expresive: word level correction is < expressive >, context correction is < expressive >\n",
      "In line 4, the word < usingenglish > was not found (no suggested corrections)\n",
      "In line 4, (com files) pdf: word level correction is < of >, context correction is < of >\n",
      "In line 4, (pdf spelling) pdf: word level correction is < of >, context correction is < of >\n",
      "-----\n",
      "total words checked: 234\n",
      "total unknown words: 2\n",
      "total potential errors found: 37\n",
      "total mismatches (word level vs. context): 11\n"
     ]
    }
   ],
   "source": [
    "correct_document_context(\"/Users/K-Lo/Desktop/usingengsample.txt\", 50, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
