{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#import scipy as sp\n",
    "#import matplotlib as mpl\n",
    "#import matplotlib.cm as cm\n",
    "#import matplotlib.pyplot as plt\n",
    "#import pandas as pd\n",
    "#import time\n",
    "#pd.set_option('display.width', 500)\n",
    "#pd.set_option('display.max_columns', 100)\n",
    "#pd.set_option('display.notebook_repr_html', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Based on SymSpell:\n",
    "\n",
    "Originally written in C#:\n",
    "\n",
    "// SymSpell: 1 million times faster through Symmetric Delete spelling correction algorithm\n",
    "//\n",
    "// The Symmetric Delete spelling correction algorithm reduces the complexity of edit candidate generation and dictionary lookup \n",
    "// for a given Damerau-Levenshtein distance. It is six orders of magnitude faster and language independent.\n",
    "// Opposite to other algorithms only deletes are required, no transposes + replaces + inserts.\n",
    "// Transposes + replaces + inserts of the input term are transformed into deletes of the dictionary term.\n",
    "// Replaces and inserts are expensive and language dependent: e.g. Chinese has 70,000 Unicode Han characters!\n",
    "//\n",
    "// Copyright (C) 2015 Wolf Garbe\n",
    "// Version: 3.0\n",
    "// Author: Wolf Garbe <wolf.garbe@faroo.com>\n",
    "// Maintainer: Wolf Garbe <wolf.garbe@faroo.com>\n",
    "// URL: http://blog.faroo.com/2012/06/07/improved-edit-distance-based-spelling-correction/\n",
    "// Description: http://blog.faroo.com/2012/06/07/improved-edit-distance-based-spelling-correction/\n",
    "//\n",
    "// License:\n",
    "// This program is free software; you can redistribute it and/or modify\n",
    "// it under the terms of the GNU Lesser General Public License, \n",
    "// version 3.0 (LGPL-3.0) as published by the Free Software Foundation.\n",
    "// http://www.opensource.org/licenses/LGPL-3.0\n",
    "//\n",
    "// Usage: single word + Enter:  Display spelling suggestions\n",
    "//        Enter without input:  Terminate the program\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import re, collections\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_edit_distance = 3\n",
    "dictionary = {}\n",
    "longest_word_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_deletes_list(w):\n",
    "    '''given a word, derive strings with up to max_edit_distance characters deleted'''\n",
    "    deletes = []\n",
    "    queue = [w]\n",
    "    for d in range(max_edit_distance):\n",
    "        temp_queue = []\n",
    "        for word in queue:\n",
    "            if len(word)>1:\n",
    "                for c in range(len(word)):  # character index\n",
    "                    word_minus_c = word[:c] + word[c+1:]\n",
    "                    if word_minus_c not in deletes:\n",
    "                        deletes.append(word_minus_c)\n",
    "                    if word_minus_c not in temp_queue:\n",
    "                        temp_queue.append(word_minus_c)\n",
    "        queue = temp_queue\n",
    "        \n",
    "    return deletes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get_deletes_list(\"tomorrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dictionary_entry(w):\n",
    "    '''add word and its derived deletions to dictionary'''\n",
    "    # check if word is already in dictionary\n",
    "    # dictionary entries are in the form: (list of suggested corrections, frequency of word in corpus)\n",
    "    global longest_word_length\n",
    "    new_real_word_added = False\n",
    "    if w in dictionary:\n",
    "        dictionary[w] = (dictionary[w][0], dictionary[w][1] + 1)  # increment count of word in corpus\n",
    "    else:\n",
    "        dictionary[w] = ([], 1)  \n",
    "        longest_word_length = max(longest_word_length, len(w))\n",
    "        \n",
    "    if dictionary[w][1]==1:\n",
    "        # first appearance of word in corpus\n",
    "        # n.b. word may already be in dictionary as a derived word (deleting character from a real word)\n",
    "        # but counter of frequency of word in corpus is not incremented in those cases)\n",
    "        new_real_word_added = True\n",
    "        deletes = get_deletes_list(w)\n",
    "        for item in deletes:\n",
    "            if item in dictionary:\n",
    "                # add (correct) word to delete's suggested correction list if not already there\n",
    "                if item not in dictionary[item][0]:\n",
    "                    dictionary[item][0].append(w)\n",
    "            else:\n",
    "                dictionary[item] = ([w], 0)  # note frequency of word in corpus is not incremented\n",
    "        \n",
    "    return new_real_word_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dictionary(fname):\n",
    "    total_word_count = 0\n",
    "    unique_word_count = 0\n",
    "    print \"Creating dictionary...\" \n",
    "    \n",
    "    with open(fname) as file:    \n",
    "        for line in file:\n",
    "            words = re.findall('[a-z]+', line.lower())  # separate by words by non-alphabetical characters      \n",
    "            for word in words:\n",
    "                total_word_count += 1\n",
    "                if create_dictionary_entry(word):\n",
    "                    unique_word_count += 1\n",
    "    \n",
    "    print \"total words processed: %i\" % total_word_count\n",
    "    print \"total unique words in corpus: %i\" % unique_word_count\n",
    "    print \"total items in dictionary (corpus words and deletions): %i\" % len(dictionary)\n",
    "    print \"  edit distance for deletions: %i\" % max_edit_distance\n",
    "    print \"  length of longest word in corpus: %i\" % longest_word_length\n",
    "        \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dictionary...\n",
      "total words processed: 1105285\n",
      "total unique words in corpus: 29157\n",
      "total items in dictionary (corpus words and deletions): 2151998\n",
      "  edit distance for deletions: 3\n",
      "  length of longest word in corpus: 18\n",
      "CPU times: user 26 s, sys: 540 ms, total: 26.5 s\n",
      "Wall time: 26.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "create_dictionary(\"/Users/K-Lo/Desktop/big.txt\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>For testing:</b> <p>\n",
    "Can look up a specific entry in the dictionary below. <br>\n",
    "shows (possible corrections, and frequency that entry itself is in corpus - 0 if not a real word) <br>\n",
    "Note: will return key error if there are no corrections (because we are accessing dictionary directly here)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 2 µs, total: 5 µs\n",
      "Wall time: 7.15 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['other',\n",
       "  'these',\n",
       "  'they',\n",
       "  'there',\n",
       "  'those',\n",
       "  'their',\n",
       "  'threw',\n",
       "  'then',\n",
       "  'either',\n",
       "  'rather',\n",
       "  'them',\n",
       "  'three',\n",
       "  'others',\n",
       "  'thief',\n",
       "  'lithe',\n",
       "  'father',\n",
       "  'mother',\n",
       "  'gather',\n",
       "  'theory',\n",
       "  'theirs',\n",
       "  'threat',\n",
       "  'thread',\n",
       "  'thames',\n",
       "  'theft',\n",
       "  'clothe',\n",
       "  'mather',\n",
       "  'throne',\n",
       "  'thesis',\n",
       "  'thrice',\n",
       "  'wythe',\n",
       "  'thence',\n",
       "  'themes',\n",
       "  'smythe',\n",
       "  'thee',\n",
       "  'thiers',\n",
       "  'theme',\n",
       "  'thecal',\n",
       "  'bathed',\n",
       "  'thermo',\n",
       "  'thrive',\n",
       "  'ether',\n",
       "  'thyreo',\n",
       "  'bathe',\n",
       "  'hither',\n",
       "  'scythe',\n",
       "  'touche',\n",
       "  'bother',\n",
       "  'soothe',\n",
       "  'lathe',\n",
       "  'nether',\n",
       "  'loathe',\n",
       "  'thaler',\n",
       "  'thresh',\n",
       "  'tache',\n",
       "  'threes',\n",
       "  'thwee',\n",
       "  'lather',\n",
       "  'thefts',\n",
       "  'thine',\n",
       "  'theah',\n",
       "  'luther',\n",
       "  'athens',\n",
       "  'esther',\n",
       "  'ethel',\n",
       "  'thebes'],\n",
       " 80030)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dictionary[\"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'zzfftf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f597a6fea902>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"zzfftf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'zzfftf'"
     ]
    }
   ],
   "source": [
    "dictionary[\"zzfftf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dameraulevenshtein(seq1, seq2):\n",
    "    \"\"\"Calculate the Damerau-Levenshtein distance between sequences.\n",
    "\n",
    "    Source: http://mwh.geek.nz/2009/04/26/python-damerau-levenshtein-distance/\n",
    "    \n",
    "    This distance is the number of additions, deletions, substitutions,\n",
    "    and transpositions needed to transform the first sequence into the\n",
    "    second. Although generally used with strings, any sequences of\n",
    "    comparable objects will work.\n",
    "\n",
    "    Transpositions are exchanges of *consecutive* characters; all other\n",
    "    operations are self-explanatory.\n",
    "\n",
    "    This implementation is O(N*M) time and O(M) space, for N and M the\n",
    "    lengths of the two sequences.\n",
    "\n",
    "    >>> dameraulevenshtein('ba', 'abc')\n",
    "    2\n",
    "    >>> dameraulevenshtein('fee', 'deed')\n",
    "    2\n",
    "\n",
    "    It works with arbitrary sequences too:\n",
    "    >>> dameraulevenshtein('abcd', ['b', 'a', 'c', 'd', 'e'])\n",
    "    2\n",
    "    \"\"\"\n",
    "    # codesnippet:D0DE4716-B6E6-4161-9219-2903BF8F547F\n",
    "    # Conceptually, this is based on a len(seq1) + 1 * len(seq2) + 1 matrix.\n",
    "    # However, only the current and two previous rows are needed at once,\n",
    "    # so we only store those.\n",
    "    oneago = None\n",
    "    thisrow = range(1, len(seq2) + 1) + [0]\n",
    "    for x in xrange(len(seq1)):\n",
    "        # Python lists wrap around for negative indices, so put the\n",
    "        # leftmost column at the *end* of the list. This matches with\n",
    "        # the zero-indexed strings and saves extra calculation.\n",
    "        twoago, oneago, thisrow = oneago, thisrow, [0] * len(seq2) + [x + 1]\n",
    "        for y in xrange(len(seq2)):\n",
    "            delcost = oneago[y] + 1\n",
    "            addcost = thisrow[y - 1] + 1\n",
    "            subcost = oneago[y - 1] + (seq1[x] != seq2[y])\n",
    "            thisrow[y] = min(delcost, addcost, subcost)\n",
    "            # This block deals with transpositions\n",
    "            if (x > 0 and y > 0 and seq1[x] == seq2[y - 1]\n",
    "                and seq1[x-1] == seq2[y] and seq1[x] != seq2[y]):\n",
    "                thisrow[y] = min(thisrow[y], twoago[y - 2] + 1)\n",
    "    return thisrow[len(seq2) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_suggestions(string, silent=False):\n",
    "    '''return list of suggested corrections for potentially incorrectly spelled word'''\n",
    "    if (len(string) - longest_word_length) > max_edit_distance:\n",
    "        if not silent:\n",
    "            print \"no items in dictionary within maximum edit distance\"\n",
    "        return []\n",
    "    \n",
    "    # suggestions = []\n",
    "    # s_dictionary = {}\n",
    "    suggest_dict = {}\n",
    "    \n",
    "    queue = [string]\n",
    "    q_dictionary = {}  # items other than string that we've checked\n",
    "    \n",
    "    while len(queue)>0:\n",
    "        q_item = queue[0]  # pop\n",
    "        # print \"processing '%s'\" % q_item\n",
    "        queue = queue[1:]\n",
    "        \n",
    "        # process queue item\n",
    "        if (q_item in dictionary) and (q_item not in suggest_dict):\n",
    "            if (dictionary[q_item][1]>0):\n",
    "            # word is in dictionary, and is a word from the corpus, and not already in suggestion list\n",
    "            # so add to suggestion dictionary, indexed by the word with value (frequency in corpus, edit distance)\n",
    "            # note q_items that are not the input string are shorter than input string \n",
    "            # since only deletes are added (unless manual dictionary corrections are added)\n",
    "                assert len(string)>=len(q_item)\n",
    "                suggest_dict[q_item] = (dictionary[q_item][1], len(string) - len(q_item))\n",
    "            \n",
    "            ## the suggested corrections for q_item as stored in dictionary (whether or not\n",
    "            ## q_item itself is a valid word or merely a delete) can be valid corrections\n",
    "            for sc_item in dictionary[q_item][0]:\n",
    "                if (sc_item not in suggest_dict):\n",
    "                    # compute edit distance\n",
    "                    # if len(sc_item)==len(q_item):\n",
    "                    #    item_dist = len(string) - len(q_item)\n",
    "                    # suggested items should always be longer (unless manual corrections are added)\n",
    "                    assert len(sc_item)>len(q_item)\n",
    "                    # q_items that are not input should be shorter than original string \n",
    "                    # (unless manual corrections added)\n",
    "                    assert len(q_item)<=len(string)\n",
    "                    if len(q_item)==len(string):\n",
    "                        assert q_item==string\n",
    "                        item_dist = len(sc_item) - len(q_item)\n",
    "                    #elif len(q_item)==len(string):\n",
    "                        # a suggestion could be longer or shorter than original string (bug in original FAROO?)\n",
    "                        # if suggestion is from string's suggestion list, sc_item will be longer\n",
    "                        # if suggestion is from a delete's suggestion list, sc_item may be shorter\n",
    "                    #   item_dist = abs(len(sc_item) - len(q_item))\n",
    "                    #else:\n",
    "                    # check in original code, but probably not necessary because string has already checked\n",
    "                    assert sc_item!=string\n",
    "                    \n",
    "                    # calculate edit distance using, for example, Damerau-Levenshtein distance\n",
    "                    item_dist = dameraulevenshtein(sc_item, string)\n",
    "                    \n",
    "                    if item_dist<=max_edit_distance:\n",
    "                        assert sc_item in dictionary  # should already be in dictionary if in suggestion list\n",
    "                        suggest_dict[sc_item] = (dictionary[sc_item][1], item_dist)\n",
    "        \n",
    "        # now generate deletes (e.g. a substring of string or of a delete) from the queue item\n",
    "        # as additional items to check -- add to end of queue\n",
    "        assert len(string)>=len(q_item)\n",
    "        if (len(string)-len(q_item))<max_edit_distance and len(q_item)>1:\n",
    "            for c in range(len(q_item)): # character index        \n",
    "                word_minus_c = q_item[:c] + q_item[c+1:]\n",
    "                if word_minus_c not in q_dictionary:\n",
    "                    queue.append(word_minus_c)\n",
    "                    q_dictionary[word_minus_c] = None  # arbitrary value, just to identify we checked this\n",
    "             \n",
    "    # queue is now empty: convert suggestions in dictionary to list for output\n",
    "    \n",
    "    if not silent:\n",
    "        print \"number of possible corrections: %i\" %len(suggest_dict)\n",
    "        print \"  edit distance for deletions: %i\" % max_edit_distance\n",
    "    \n",
    "    # output option 1\n",
    "    # sort results by ascending order of edit distance and descending order of frequency\n",
    "    #     and return list of suggested corrections only:\n",
    "    # return sorted(suggest_dict, key = lambda x: (suggest_dict[x][1], -suggest_dict[x][0]))\n",
    "\n",
    "    # output option 2\n",
    "    # return list of suggestions with (correction, (frequency in corpus, edit distance)):\n",
    "    as_list = suggest_dict.items()\n",
    "    return sorted(as_list, key = lambda (term, (freq, dist)): (dist, -freq))\n",
    "\n",
    "    '''\n",
    "    Option 1:\n",
    "    get_suggestions(\"file\")\n",
    "    ['file', 'five', 'fire', 'fine', ...]\n",
    "    \n",
    "    Option 2:\n",
    "    get_suggestions(\"file\")\n",
    "    [('file', (5, 0)),\n",
    "     ('five', (67, 1)),\n",
    "     ('fire', (54, 1)),\n",
    "     ('fine', (17, 1))...]  \n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>For testing:</b><p>\n",
    "Type in word to correct below, to test and get whole list of possible suggestions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of possible corrections: 604\n",
      "  edit distance for deletions: 3\n",
      "CPU times: user 60.3 ms, sys: 11.3 ms, total: 71.6 ms\n",
      "Wall time: 63 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('there', (2972, 0)),\n",
       " ('these', (1231, 1)),\n",
       " ('where', (977, 1)),\n",
       " ('here', (691, 1)),\n",
       " ('three', (584, 1)),\n",
       " ('thee', (26, 1)),\n",
       " ('chere', (9, 1)),\n",
       " ('theme', (8, 1)),\n",
       " ('the', (80030, 2)),\n",
       " ('her', (5284, 2)),\n",
       " ('were', (4289, 2)),\n",
       " ('they', (3938, 2)),\n",
       " ('their', (2955, 2)),\n",
       " ('them', (2241, 2)),\n",
       " ('then', (1558, 2)),\n",
       " ('other', (1502, 2)),\n",
       " ('those', (1201, 2)),\n",
       " ('others', (410, 2)),\n",
       " ('third', (239, 2)),\n",
       " ('term', (133, 2)),\n",
       " ('threw', (96, 2)),\n",
       " ('theory', (79, 2)),\n",
       " ('mere', (79, 2)),\n",
       " ('share', (69, 2)),\n",
       " ('hero', (55, 2)),\n",
       " ('tree', (42, 2)),\n",
       " ('hare', (36, 2)),\n",
       " ('thereby', (32, 2)),\n",
       " ('sphere', (31, 2)),\n",
       " ('hers', (30, 2)),\n",
       " ('thereof', (26, 2)),\n",
       " ('cher', (25, 2)),\n",
       " ('tore', (18, 2)),\n",
       " ('herd', (15, 2)),\n",
       " ('theirs', (14, 2)),\n",
       " ('thiers', (13, 2)),\n",
       " ('shore', (11, 2)),\n",
       " ('thence', (10, 2)),\n",
       " ('tete', (9, 2)),\n",
       " ('adhere', (8, 2)),\n",
       " ('sheer', (8, 2)),\n",
       " ('ether', (8, 2)),\n",
       " ('tver', (7, 2)),\n",
       " ('therein', (6, 2)),\n",
       " ('herb', (5, 2)),\n",
       " ('tier', (5, 2)),\n",
       " ('thermo', (5, 2)),\n",
       " ('cheer', (5, 2)),\n",
       " ('hire', (5, 2)),\n",
       " ('threes', (4, 2)),\n",
       " ('pere', (4, 2)),\n",
       " ('theatre', (4, 2)),\n",
       " ('themes', (3, 2)),\n",
       " ('theresa', (3, 2)),\n",
       " ('herr', (3, 2)),\n",
       " ('thwee', (3, 2)),\n",
       " ('thine', (3, 2)),\n",
       " ('tire', (3, 2)),\n",
       " ('theft', (3, 2)),\n",
       " ('teres', (3, 2)),\n",
       " ('vere', (2, 2)),\n",
       " ('frere', (2, 2)),\n",
       " ('thorn', (2, 2)),\n",
       " ('dere', (1, 2)),\n",
       " ('zere', (1, 2)),\n",
       " ('ere', (1, 2)),\n",
       " ('tierce', (1, 2)),\n",
       " ('thereon', (1, 2)),\n",
       " ('thereto', (1, 2)),\n",
       " ('tyre', (1, 2)),\n",
       " ('tiers', (1, 2)),\n",
       " ('theah', (1, 2)),\n",
       " ('thebes', (1, 2)),\n",
       " ('terse', (1, 2)),\n",
       " ('thyreo', (1, 2)),\n",
       " ('that', (12512, 3)),\n",
       " ('he', (12401, 3)),\n",
       " ('this', (4063, 3)),\n",
       " ('she', (3946, 3)),\n",
       " ('are', (3630, 3)),\n",
       " ('have', (3493, 3)),\n",
       " ('when', (2923, 3)),\n",
       " ('more', (1997, 3)),\n",
       " ('pierre', (1964, 3)),\n",
       " ('time', (1529, 3)),\n",
       " ('very', (1340, 3)),\n",
       " ('over', (1282, 3)),\n",
       " ('than', (1206, 3)),\n",
       " ('see', (1101, 3)),\n",
       " ('while', (768, 3)),\n",
       " ('whole', (744, 3)),\n",
       " ('head', (725, 3)),\n",
       " ('every', (650, 3)),\n",
       " ('heard', (636, 3)),\n",
       " ('take', (616, 3)),\n",
       " ('think', (557, 3)),\n",
       " ('father', (533, 3)),\n",
       " ('tell', (492, 3)),\n",
       " ('free', (421, 3)),\n",
       " ('white', (353, 3)),\n",
       " ('horse', (334, 3)),\n",
       " ('nerve', (324, 3)),\n",
       " ('mother', (312, 3)),\n",
       " ('thing', (303, 3)),\n",
       " ('table', (296, 3)),\n",
       " ('home', (295, 3)),\n",
       " ('either', (293, 3)),\n",
       " ('held', (287, 3)),\n",
       " ('ever', (274, 3)),\n",
       " ('fire', (274, 3)),\n",
       " ('heart', (256, 3)),\n",
       " ('short', (236, 3)),\n",
       " ('help', (230, 3)),\n",
       " ('ten', (219, 3)),\n",
       " ('rather', (219, 3)),\n",
       " ('trade', (217, 3)),\n",
       " ('thus', (212, 3)),\n",
       " ('true', (205, 3)),\n",
       " ('re', (189, 3)),\n",
       " ('whose', (188, 3)),\n",
       " ('turn', (188, 3)),\n",
       " ('hear', (183, 3)),\n",
       " ('hard', (180, 3)),\n",
       " ('severe', (173, 3)),\n",
       " ('tears', (172, 3)),\n",
       " ('knee', (171, 3)),\n",
       " ('thin', (166, 3)),\n",
       " ('tone', (166, 3)),\n",
       " ('hope', (149, 3)),\n",
       " ('terms', (148, 3)),\n",
       " ('thirty', (123, 3)),\n",
       " ('sure', (123, 3)),\n",
       " ('eye', (110, 3)),\n",
       " ('tea', (107, 3)),\n",
       " ('care', (106, 3)),\n",
       " ('thank', (105, 3)),\n",
       " ('berg', (98, 3)),\n",
       " ('huge', (89, 3)),\n",
       " ('try', (87, 3)),\n",
       " ('type', (87, 3)),\n",
       " ('per', (86, 3)),\n",
       " ('twice', (84, 3)),\n",
       " ('sharp', (83, 3)),\n",
       " ('heat', (83, 3)),\n",
       " ('rare', (83, 3)),\n",
       " ('sore', (81, 3)),\n",
       " ('chest', (81, 3)),\n",
       " ('thick', (77, 3)),\n",
       " ('agree', (77, 3)),\n",
       " ('teeth', (76, 3)),\n",
       " ('vera', (75, 3)),\n",
       " ('bare', (74, 3)),\n",
       " ('shed', (74, 3)),\n",
       " ('cure', (71, 3)),\n",
       " ('charge', (70, 3)),\n",
       " ('stern', (65, 3)),\n",
       " ('serve', (64, 3)),\n",
       " ('shape', (62, 3)),\n",
       " ('piece', (61, 3)),\n",
       " ('torn', (60, 3)),\n",
       " ('gathered', (59, 3)),\n",
       " ('wore', (58, 3)),\n",
       " ('uttered', (58, 3)),\n",
       " ('tsar', (56, 3)),\n",
       " ('pure', (54, 3)),\n",
       " ('test', (53, 3)),\n",
       " ('tend', (52, 3)),\n",
       " ('aware', (52, 3)),\n",
       " ('toes', (51, 3)),\n",
       " ('th', (51, 3)),\n",
       " ('henry', (51, 3)),\n",
       " ('thumb', (51, 3)),\n",
       " ('trees', (51, 3)),\n",
       " ('shirt', (50, 3)),\n",
       " ('scene', (49, 3)),\n",
       " ('hart', (49, 3)),\n",
       " ('throw', (48, 3)),\n",
       " ('thy', (47, 3)),\n",
       " ('bore', (46, 3)),\n",
       " ('tube', (45, 3)),\n",
       " ('thirds', (43, 3)),\n",
       " ('ahead', (43, 3)),\n",
       " ('cheek', (43, 3)),\n",
       " ('dare', (43, 3)),\n",
       " ('twelve', (43, 3)),\n",
       " ('harm', (42, 3)),\n",
       " ('thou', (42, 3)),\n",
       " ('shone', (41, 3)),\n",
       " ('shell', (41, 3)),\n",
       " ('utter', (41, 3)),\n",
       " ('tired', (40, 3)),\n",
       " ('hide', (40, 3)),\n",
       " ('tied', (40, 3)),\n",
       " ('heal', (40, 3)),\n",
       " ('title', (39, 3)),\n",
       " ('thigh', (39, 3)),\n",
       " ('wheat', (38, 3)),\n",
       " ('check', (38, 3)),\n",
       " ('toe', (36, 3)),\n",
       " ('trace', (36, 3)),\n",
       " ('shade', (35, 3)),\n",
       " ('chose', (34, 3)),\n",
       " ('hurt', (34, 3)),\n",
       " ('peri', (33, 3)),\n",
       " ('tide', (33, 3)),\n",
       " ('rhode', (33, 3)),\n",
       " ('sire', (32, 3)),\n",
       " ('hence', (32, 3)),\n",
       " ('shame', (32, 3)),\n",
       " ('charm', (31, 3)),\n",
       " ('treat', (31, 3)),\n",
       " ('eve', (30, 3)),\n",
       " ('sheet', (29, 3)),\n",
       " ('fee', (29, 3)),\n",
       " ('theodore', (28, 3)),\n",
       " ('lee', (27, 3)),\n",
       " ('spare', (27, 3)),\n",
       " ('text', (26, 3)),\n",
       " ('throne', (26, 3)),\n",
       " ('shared', (25, 3)),\n",
       " ('heroes', (25, 3)),\n",
       " ('scheme', (25, 3)),\n",
       " ('theater', (25, 3)),\n",
       " ('clerk', (25, 3)),\n",
       " ('tear', (24, 3)),\n",
       " ('ties', (24, 3)),\n",
       " ('sheep', (24, 3)),\n",
       " ('bier', (24, 3)),\n",
       " ('tent', (24, 3)),\n",
       " ('nowhere', (24, 3)),\n",
       " ('wire', (23, 3)),\n",
       " ('tense', (23, 3)),\n",
       " ('whence', (23, 3)),\n",
       " ('taste', (23, 3)),\n",
       " ('hive', (21, 3)),\n",
       " ('theories', (21, 3)),\n",
       " ('tenure', (21, 3)),\n",
       " ('tale', (21, 3)),\n",
       " ('niece', (21, 3)),\n",
       " ('wheel', (21, 3)),\n",
       " ('heel', (21, 3)),\n",
       " ('phase', (21, 3)),\n",
       " ('hate', (20, 3)),\n",
       " ('chase', (20, 3)),\n",
       " ('gather', (19, 3)),\n",
       " ('thorax', (19, 3)),\n",
       " ('horn', (18, 3)),\n",
       " ('hole', (18, 3)),\n",
       " ('irene', (18, 3)),\n",
       " ('fathers', (18, 3)),\n",
       " ('geese', (18, 3)),\n",
       " ('truce', (17, 3)),\n",
       " ('score', (17, 3)),\n",
       " ('heap', (17, 3)),\n",
       " ('thread', (16, 3)),\n",
       " ('serf', (16, 3)),\n",
       " ('tens', (16, 3)),\n",
       " ('tyler', (15, 3)),\n",
       " ('termed', (15, 3)),\n",
       " ('bee', (15, 3)),\n",
       " ('pre', (15, 3)),\n",
       " ('cheap', (15, 3)),\n",
       " ('queer', (15, 3)),\n",
       " ('tune', (15, 3)),\n",
       " ('heed', (15, 3)),\n",
       " ('tie', (15, 3)),\n",
       " ('shake', (14, 3)),\n",
       " ('tavern', (14, 3)),\n",
       " ('erie', (14, 3)),\n",
       " ('thirst', (13, 3)),\n",
       " ('teno', (13, 3)),\n",
       " ('pierce', (13, 3)),\n",
       " ('alert', (13, 3)),\n",
       " ('mothers', (12, 3)),\n",
       " ('store', (12, 3)),\n",
       " ('hue', (12, 3)),\n",
       " ('chart', (12, 3)),\n",
       " ('tour', (12, 3)),\n",
       " ('tread', (12, 3)),\n",
       " ('fierce', (12, 3)),\n",
       " ('thief', (12, 3)),\n",
       " ('moore', (12, 3)),\n",
       " ('rhine', (12, 3)),\n",
       " ('hemp', (11, 3)),\n",
       " ('hears', (11, 3)),\n",
       " ('fete', (11, 3)),\n",
       " ('flee', (11, 3)),\n",
       " ('opera', (11, 3)),\n",
       " ('threat', (11, 3)),\n",
       " ('shoe', (11, 3)),\n",
       " ('whereas', (11, 3)),\n",
       " ('avert', (11, 3)),\n",
       " ('cheered', (10, 3)),\n",
       " ('heir', (10, 3)),\n",
       " ('acre', (10, 3)),\n",
       " ('era', (10, 3)),\n",
       " ('thud', (10, 3)),\n",
       " ('hey', (10, 3)),\n",
       " ('shores', (9, 3)),\n",
       " ('sera', (9, 3)),\n",
       " ('beer', (9, 3)),\n",
       " ('cherry', (9, 3)),\n",
       " ('tower', (9, 3)),\n",
       " ('sabre', (9, 3)),\n",
       " ('lure', (8, 3)),\n",
       " ('trend', (8, 3)),\n",
       " ('emerge', (8, 3)),\n",
       " ('verge', (8, 3)),\n",
       " ('harp', (8, 3)),\n",
       " ('thieves', (8, 3)),\n",
       " ('faire', (8, 3)),\n",
       " ('siege', (8, 3)),\n",
       " ('team', (8, 3)),\n",
       " ('chyle', (8, 3)),\n",
       " ('fiery', (8, 3)),\n",
       " ('shelf', (8, 3)),\n",
       " ('exert', (8, 3)),\n",
       " ('thrice', (8, 3)),\n",
       " ('weren', (8, 3)),\n",
       " ('heirs', (8, 3)),\n",
       " ('user', (8, 3)),\n",
       " ('whereby', (8, 3)),\n",
       " ('ushered', (8, 3)),\n",
       " ('verse', (8, 3)),\n",
       " ('tar', (7, 3)),\n",
       " ('fare', (7, 3)),\n",
       " ('swore', (7, 3)),\n",
       " ('averse', (7, 3)),\n",
       " ('hired', (7, 3)),\n",
       " ('core', (7, 3)),\n",
       " ('scherer', (7, 3)),\n",
       " ('germ', (7, 3)),\n",
       " ('tweed', (6, 3)),\n",
       " ('jerk', (6, 3)),\n",
       " ('spheres', (6, 3)),\n",
       " ('merge', (6, 3)),\n",
       " ('sherren', (6, 3)),\n",
       " ('sneer', (6, 3)),\n",
       " ('sero', (6, 3)),\n",
       " ('withered', (6, 3)),\n",
       " ('howe', (6, 3)),\n",
       " ('helen', (6, 3)),\n",
       " ('whirl', (6, 3)),\n",
       " ('cheers', (6, 3)),\n",
       " ('tinge', (6, 3)),\n",
       " ('chord', (6, 3)),\n",
       " ('shove', (6, 3)),\n",
       " ('hen', (6, 3)),\n",
       " ('whew', (6, 3)),\n",
       " ('zero', (5, 3)),\n",
       " ('der', (5, 3)),\n",
       " ('hither', (5, 3)),\n",
       " ('sheds', (5, 3)),\n",
       " ('erb', (5, 3)),\n",
       " ('wharf', (5, 3)),\n",
       " ('ordre', (5, 3)),\n",
       " ('cheese', (5, 3)),\n",
       " ('tory', (5, 3)),\n",
       " ('adhered', (5, 3)),\n",
       " ('mare', (5, 3)),\n",
       " ('taper', (5, 3)),\n",
       " ('chess', (5, 3)),\n",
       " ('glare', (5, 3)),\n",
       " ('peered', (5, 3)),\n",
       " ('stare', (5, 3)),\n",
       " ('deer', (5, 3)),\n",
       " ('er', (5, 3)),\n",
       " ('inert', (4, 3)),\n",
       " ('haze', (4, 3)),\n",
       " ('attire', (4, 3)),\n",
       " ('peru', (4, 3)),\n",
       " ('thorns', (4, 3)),\n",
       " ('tribe', (4, 3)),\n",
       " ('hell', (4, 3)),\n",
       " ('whereof', (4, 3)),\n",
       " ('heave', (4, 3)),\n",
       " ('bother', (4, 3)),\n",
       " ('tres', (4, 3)),\n",
       " ('steer', (4, 3)),\n",
       " ('cheat', (4, 3)),\n",
       " ('hedge', (4, 3)),\n",
       " ('etre', (4, 3)),\n",
       " ('rete', (4, 3)),\n",
       " ('herein', (4, 3)),\n",
       " ('hebrew', (4, 3)),\n",
       " ('zheg', (4, 3)),\n",
       " ('wherein', (4, 3)),\n",
       " ('overt', (4, 3)),\n",
       " ('peer', (4, 3)),\n",
       " ('hem', (4, 3)),\n",
       " ('tapers', (4, 3)),\n",
       " ('adore', (4, 3)),\n",
       " ('users', (4, 3)),\n",
       " ('shine', (4, 3)),\n",
       " ('query', (3, 3)),\n",
       " ('tethered', (3, 3)),\n",
       " ('shave', (3, 3)),\n",
       " ('shares', (3, 3)),\n",
       " ('towers', (3, 3)),\n",
       " ('ware', (3, 3)),\n",
       " ('whale', (3, 3)),\n",
       " ('notre', (3, 3)),\n",
       " ('thecal', (3, 3)),\n",
       " ('glee', (3, 3)),\n",
       " ('dire', (3, 3)),\n",
       " ('ore', (3, 3)),\n",
       " ('turk', (3, 3)),\n",
       " ('turf', (3, 3)),\n",
       " ('scare', (3, 3)),\n",
       " ('herds', (3, 3)),\n",
       " ('hors', (3, 3)),\n",
       " ('ashore', (3, 3)),\n",
       " ('spore', (3, 3)),\n",
       " ('tenn', (3, 3)),\n",
       " ('thierry', (3, 3)),\n",
       " ('oder', (3, 3)),\n",
       " ('barre', (3, 3)),\n",
       " ('fera', (3, 3)),\n",
       " ('tiger', (3, 3)),\n",
       " ('chale', (3, 3)),\n",
       " ('cheery', (3, 3)),\n",
       " ('tilde', (3, 3)),\n",
       " ('wee', (3, 3)),\n",
       " ('pier', (3, 3)),\n",
       " ('tease', (3, 3)),\n",
       " ('tsars', (3, 3)),\n",
       " ('andre', (2, 3)),\n",
       " ('ver', (2, 3)),\n",
       " ('rhyme', (2, 3)),\n",
       " ('verb', (2, 3)),\n",
       " ('withers', (2, 3)),\n",
       " ('ted', (2, 3)),\n",
       " ('spire', (2, 3)),\n",
       " ('veered', (2, 3)),\n",
       " ('outre', (2, 3)),\n",
       " ('hereby', (2, 3)),\n",
       " ('err', (2, 3)),\n",
       " ('athlete', (2, 3)),\n",
       " ('gathers', (2, 3)),\n",
       " ('hume', (2, 3)),\n",
       " ('piers', (2, 3)),\n",
       " ('votre', (2, 3)),\n",
       " ('shred', (2, 3)),\n",
       " ('thesis', (2, 3)),\n",
       " ('tache', (2, 3)),\n",
       " ('hark', (2, 3)),\n",
       " ('beri', (2, 3)),\n",
       " ('spree', (2, 3)),\n",
       " ('garre', (2, 3)),\n",
       " ('thaw', (2, 3)),\n",
       " ('thresh', (2, 3)),\n",
       " ('hur', (2, 3)),\n",
       " ('lather', (2, 3)),\n",
       " ('chef', (2, 3)),\n",
       " ('hearer', (2, 3)),\n",
       " ('sacre', (2, 3)),\n",
       " ('horde', (2, 3)),\n",
       " ('sherry', (2, 3)),\n",
       " ('shorn', (2, 3)),\n",
       " ('peers', (2, 3)),\n",
       " ('fibre', (2, 3)),\n",
       " ('hares', (2, 3)),\n",
       " ('tape', (2, 3)),\n",
       " ('adheres', (2, 3)),\n",
       " ('guerre', (2, 3)),\n",
       " ('seers', (2, 3)),\n",
       " ('thrive', (2, 3)),\n",
       " ('tra', (2, 3)),\n",
       " ('hewn', (2, 3)),\n",
       " ('whine', (2, 3)),\n",
       " ('whirr', (2, 3)),\n",
       " ('doers', (2, 3)),\n",
       " ('jeered', (2, 3)),\n",
       " ('coerce', (2, 3)),\n",
       " ('tendre', (2, 3)),\n",
       " ('throb', (2, 3)),\n",
       " ('herpes', (2, 3)),\n",
       " ('choke', (2, 3)),\n",
       " ('azure', (2, 3)),\n",
       " ('treble', (2, 3)),\n",
       " ('heresy', (2, 3)),\n",
       " ('heh', (2, 3)),\n",
       " ('neve', (2, 3)),\n",
       " ('cheque', (2, 3)),\n",
       " ('phone', (2, 3)),\n",
       " ('thames', (2, 3)),\n",
       " ('tarry', (1, 3)),\n",
       " ('theorise', (1, 3)),\n",
       " ('madere', (1, 3)),\n",
       " ('lore', (1, 3)),\n",
       " ('te', (1, 3)),\n",
       " ('esther', (1, 3)),\n",
       " ('vert', (1, 3)),\n",
       " ('steve', (1, 3)),\n",
       " ('trite', (1, 3)),\n",
       " ('hesse', (1, 3)),\n",
       " ('chew', (1, 3)),\n",
       " ('tires', (1, 3)),\n",
       " ('hyde', (1, 3)),\n",
       " ('nee', (1, 3)),\n",
       " ('mele', (1, 3)),\n",
       " ('tarred', (1, 3)),\n",
       " ('luther', (1, 3)),\n",
       " ('metre', (1, 3)),\n",
       " ('queue', (1, 3)),\n",
       " ('gene', (1, 3)),\n",
       " ('clare', (1, 3)),\n",
       " ('tr', (1, 3)),\n",
       " ('hereof', (1, 3)),\n",
       " ('chafe', (1, 3)),\n",
       " ('etherege', (1, 3)),\n",
       " ('mather', (1, 3)),\n",
       " ('thins', (1, 3)),\n",
       " ('henri', (1, 3)),\n",
       " ('thaler', (1, 3)),\n",
       " ('nether', (1, 3)),\n",
       " ('phoebe', (1, 3)),\n",
       " ('galere', (1, 3)),\n",
       " ('litre', (1, 3)),\n",
       " ('lyre', (1, 3)),\n",
       " ('chorea', (1, 3)),\n",
       " ('tile', (1, 3)),\n",
       " ('charme', (1, 3)),\n",
       " ('padre', (1, 3)),\n",
       " ('utero', (1, 3)),\n",
       " ('gee', (1, 3)),\n",
       " ('rire', (1, 3)),\n",
       " ('inheres', (1, 3)),\n",
       " ('thermal', (1, 3)),\n",
       " ('helm', (1, 3)),\n",
       " ('sheaf', (1, 3)),\n",
       " ('hewed', (1, 3)),\n",
       " ('tiara', (1, 3)),\n",
       " ('therapy', (1, 3)),\n",
       " ('heah', (1, 3)),\n",
       " ('towered', (1, 3)),\n",
       " ('thwart', (1, 3)),\n",
       " ('autre', (1, 3)),\n",
       " ('mete', (1, 3)),\n",
       " ('steered', (1, 3)),\n",
       " ('herder', (1, 3)),\n",
       " ('hew', (1, 3)),\n",
       " ('flare', (1, 3)),\n",
       " ('tate', (1, 3)),\n",
       " ('utters', (1, 3)),\n",
       " ('meme', (1, 3)),\n",
       " ('wert', (1, 3)),\n",
       " ('vierge', (1, 3)),\n",
       " ('sheen', (1, 3)),\n",
       " ('trent', (1, 3)),\n",
       " ('adele', (1, 3)),\n",
       " ('berne', (1, 3)),\n",
       " ('chary', (1, 3)),\n",
       " ('shale', (1, 3)),\n",
       " ('sterne', (1, 3)),\n",
       " ('luthers', (1, 3)),\n",
       " ('chiene', (1, 3)),\n",
       " ('chewed', (1, 3)),\n",
       " ('boire', (1, 3)),\n",
       " ('truer', (1, 3)),\n",
       " ('sexe', (1, 3)),\n",
       " ('hise', (1, 3)),\n",
       " ('ire', (1, 3)),\n",
       " ('diese', (1, 3)),\n",
       " ('trove', (1, 3)),\n",
       " ('ethel', (1, 3)),\n",
       " ('ghent', (1, 3)),\n",
       " ('tiens', (1, 3)),\n",
       " ('obese', (1, 3)),\n",
       " ('chile', (1, 3)),\n",
       " ('amene', (1, 3)),\n",
       " ('yore', (1, 3)),\n",
       " ('tyne', (1, 3)),\n",
       " ('twue', (1, 3)),\n",
       " ('hale', (1, 3)),\n",
       " ('boer', (1, 3)),\n",
       " ('avare', (1, 3)),\n",
       " ('yer', (1, 3)),\n",
       " ('quire', (1, 3)),\n",
       " ('afore', (1, 3)),\n",
       " ('snare', (1, 3)),\n",
       " ('tante', (1, 3)),\n",
       " ('snore', (1, 3)),\n",
       " ('shew', (1, 3)),\n",
       " ('usher', (1, 3)),\n",
       " ('freer', (1, 3)),\n",
       " ('ober', (1, 3)),\n",
       " ('wheal', (1, 3)),\n",
       " ('gare', (1, 3)),\n",
       " ('athens', (1, 3)),\n",
       " ('chime', (1, 3)),\n",
       " ('crewe', (1, 3)),\n",
       " ('swede', (1, 3)),\n",
       " ('tame', (1, 3)),\n",
       " ('euer', (1, 3)),\n",
       " ('tigers', (1, 3)),\n",
       " ('fore', (1, 3)),\n",
       " ('tonne', (1, 3)),\n",
       " ('thwow', (1, 3)),\n",
       " ('eerie', (1, 3)),\n",
       " ('teemed', (1, 3)),\n",
       " ('toured', (1, 3)),\n",
       " ('thefts', (1, 3)),\n",
       " ('thoreau', (1, 3))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_suggestions(\"there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "get_suggestions(\"chacha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#benchmark timing\n",
    "for i in range(1000):\n",
    "    get_suggestions(\"acamodation\", silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#benchmark timing\n",
    "for i in range(1000):\n",
    "    get_suggestions(\"acomodation\", silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#benchmark timing\n",
    "for i in range(1000):\n",
    "    get_suggestions(\"hous\", silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get best word\n",
    "def best_word(s, silent=False):\n",
    "    try:\n",
    "        return get_suggestions(s, silent)[0]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>For testing:</b><p>\n",
    "Type in word to correct below, to test and get most suggested word.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_word(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct_document(fname):\n",
    "    with open(fname) as file:\n",
    "        doc_word_count = 0\n",
    "        corrected_word_count = 0\n",
    "        unknown_word_count = 0\n",
    "        print \"Finding misspelled words in your document...\" \n",
    "        \n",
    "        for i, line in enumerate(file):\n",
    "            doc_words = re.findall('[a-z]+', line.lower())  # separate by words by non-alphabetical characters      \n",
    "            for doc_word in doc_words:\n",
    "                doc_word_count += 1\n",
    "                suggestion = best_word(doc_word, silent=True)\n",
    "                if suggestion is None:\n",
    "                    print \"In line %i, the word %s was not found (no suggested correction)\" % (i, doc_word)\n",
    "                    unknown_word_count += 1\n",
    "                elif suggestion[0]!=doc_word:\n",
    "                    print \"In line %i, %s: suggested correction is %s\" % (i, doc_word, suggestion[0])\n",
    "                    corrected_word_count += 1\n",
    "        \n",
    "    print \"-----\"\n",
    "    print \"total words checked: %i\" % doc_word_count\n",
    "    print \"total potential errors found: %i\" % corrected_word_count\n",
    "    print \"total unknown words: %i\" % unknown_word_count\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>For testing:</b><p>\n",
    "Provide test text file to correct, and give best suggestion (word level correction only) for errors.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct_document(\"/Users/K-Lo/Desktop/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from http://www.columbia.edu/acis/cria/rosenberg/sample/\n",
    "correct_document(\"/Users/K-Lo/Desktop/OCRsample.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
