{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#import scipy as sp\n",
    "#import matplotlib as mpl\n",
    "#import matplotlib.cm as cm\n",
    "#import matplotlib.pyplot as plt\n",
    "#import pandas as pd\n",
    "#import time\n",
    "#pd.set_option('display.width', 500)\n",
    "#pd.set_option('display.max_columns', 100)\n",
    "#pd.set_option('display.notebook_repr_html', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import re, collections\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_edit_distance = 2\n",
    "dictionary = {}\n",
    "longest_word_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_deletes_list(w):\n",
    "    '''given a word, derive strings with up to max_edit_distance characters deleted'''\n",
    "    deletes = []\n",
    "    queue = [w]\n",
    "    for d in range(max_edit_distance):\n",
    "        temp_queue = []\n",
    "        for word in queue:\n",
    "            if len(word)>1:\n",
    "                for c in range(len(word)):  # character index\n",
    "                    word_minus_c = word[:c] + word[c+1:]\n",
    "                    if word_minus_c not in deletes:\n",
    "                        deletes.append(word_minus_c)\n",
    "                    if word_minus_c not in temp_queue:\n",
    "                        temp_queue.append(word_minus_c)\n",
    "        queue = temp_queue\n",
    "        \n",
    "    return deletes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get_deletes_list(\"tomorrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dictionary_entry(w):\n",
    "    '''add word and its derived deletions to dictionary'''\n",
    "    # check if word is already in dictionary\n",
    "    # dictionary entries are in the form: (list of suggested corrections, frequency of word in corpus)\n",
    "    global longest_word_length\n",
    "    new_real_word_added = False\n",
    "    if w in dictionary:\n",
    "        dictionary[w] = (dictionary[w][0], dictionary[w][1] + 1)  # increment count of word in corpus\n",
    "    else:\n",
    "        dictionary[w] = ([], 1)  \n",
    "        longest_word_length = max(longest_word_length, len(w))\n",
    "        \n",
    "    if dictionary[w][1]==1:\n",
    "        # first appearance of word in corpus\n",
    "        # n.b. word may already be in dictionary as a derived word (deleting character from a real word)\n",
    "        # but counter of frequency of word in corpus is not incremented in those cases)\n",
    "        new_real_word_added = True\n",
    "        deletes = get_deletes_list(w)\n",
    "        for item in deletes:\n",
    "            if item in dictionary:\n",
    "                # add (correct) word to delete's suggested correction list if not already there\n",
    "                if item not in dictionary[item][0]:\n",
    "                    dictionary[item][0].append(w)\n",
    "            else:\n",
    "                dictionary[item] = ([w], 0)  # note frequency of word in corpus is not incremented\n",
    "        \n",
    "    return new_real_word_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dictionary(fname):\n",
    "    with open(fname) as file:\n",
    "        word_count = 0\n",
    "        print \"Creating dictionary...\" \n",
    "        \n",
    "        for line in file:\n",
    "            words = re.findall('[a-z]+', line.lower())  # separate by words by non-alphabetical characters      \n",
    "            for word in words:\n",
    "                if create_dictionary_entry(word):\n",
    "                    word_count += 1\n",
    "                    \n",
    "        print (\"total unique words in corpus: %i\" % word_count)\n",
    "        print (\"total items in dictionary (corpus words and deletions): %i\" % len(dictionary))\n",
    "        print (\"  edit distance for deletions: %i\" % max_edit_distance)\n",
    "        print (\"  length of longest word in corpus: %i\" % longest_word_length)\n",
    "        \n",
    "        return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 3.81 µs\n",
      "Creating dictionary...\n",
      "total unique words in corpus: 12020\n",
      "total items in dictionary (corpus words and deletions): 323605\n",
      "  edit distance for deletions: 2\n",
      "  length of longest word in corpus: 18\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "create_dictionary(\"/Users/K-Lo/Desktop/smaller.txt\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['baker',\n",
       "  'bear',\n",
       "  'board',\n",
       "  'bears',\n",
       "  'bark',\n",
       "  'beard',\n",
       "  'bars',\n",
       "  'bare',\n",
       "  'briar',\n",
       "  'barre',\n",
       "  'barry',\n",
       "  'baron'],\n",
       " 14)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[\"bar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pinciples': (['principles'], 0),\n",
       " 'samul': (['samuel'], 0),\n",
       " 'fahoned': (['fashioned'], 0),\n",
       " 'ecipients': (['recipients'], 0),\n",
       " 'woodd': (['wooded'], 0),\n",
       " 'woode': (['wooden', 'wooded'], 0),\n",
       " 'prosprous': (['prosperous'], 0),\n",
       " 'woodn': (['wooden'], 0),\n",
       " 'woodo': (['woodrow'], 0),\n",
       " 'commdties': (['commodities'], 0),\n",
       " 'woodr': (['woodrow'], 0),\n",
       " 'woods': ([], 7),\n",
       " 'sunde': (['sounded'], 0),\n",
       " 'intgue': (['intrigue'], 0),\n",
       " 'quesins': (['questions'], 0),\n",
       " 'deerous': (['dexterous'], 0),\n",
       " 'cmlimentary': (['complimentary'], 0),\n",
       " 'sterity': (['posterity'], 0),\n",
       " 'insensiblty': (['insensibility'], 0),\n",
       " 'atenation': (['alternation'], 0),\n",
       " 'emptie': (['emptied'], 0),\n",
       " 'canes': (['chances', 'changes', 'candles'], 0),\n",
       " 'canet': (['cabinet'], 0),\n",
       " 'fundatios': (['foundations'], 0),\n",
       " 'uccesor': (['successor'], 0),\n",
       " 'erfectly': (['perfectly'], 0),\n",
       " 'acurately': (['accurately'], 0),\n",
       " 'nvaribly': (['invariably'], 0),\n",
       " 'absrbd': (['absorbed'], 0),\n",
       " 'absrbe': (['absorbed'], 0),\n",
       " 'nvarible': (['invariable'], 0),\n",
       " 'itructed': (['instructed'], 0),\n",
       " 'caned': (['changed', 'chanced', 'cleaned', 'canned'], 0),\n",
       " 'fundation': (['foundation', 'foundations'], 0),\n",
       " 'bewidered': (['bewildered'], 0),\n",
       " 'staght': (['straight'], 0),\n",
       " 'feaherd': (['feathered'], 0),\n",
       " 'feahere': (['feathered'], 0),\n",
       " 'dvocating': (['advocating'], 0),\n",
       " 'canel': (['channel'], 0),\n",
       " 'cmpanon': (['companion'], 0),\n",
       " 'tandrds': (['standards'], 0),\n",
       " 'famiies': (['families'], 0),\n",
       " 'expeiencig': (['experiencing'], 0),\n",
       " 'impuliely': (['impulsively'], 0),\n",
       " 'egeneratng': (['degenerating'], 0),\n",
       " 'extincon': (['extinction'], 0),\n",
       " 'pigmens': (['pigments'], 0),\n",
       " 'financaly': (['financially'], 0),\n",
       " 'ubjcts': (['subjects'], 0),\n",
       " 'pigment': (['pigments'], 0),\n",
       " 'ideify': (['identify'], 0),\n",
       " 'sunds': (['sounds', 'sundays'], 0),\n",
       " 'uietly': (['quietly'], 0),\n",
       " 'neurls': (['neutrals'], 0),\n",
       " 'varible': (['variable'], 0),\n",
       " 'suggestienes': (['suggestiveness'], 0),\n",
       " 'counsels': ([], 2),\n",
       " 'omeward': (['homeward'], 0),\n",
       " 'emperamental': (['temperamental'], 0),\n",
       " 'stablsh': (['establish'], 0),\n",
       " 'rohbitions': (['prohibitions'], 0),\n",
       " 'bringing': ([], 10),\n",
       " 'exptions': (['exceptions'], 0),\n",
       " 'brodst': (['broadest'], 0),\n",
       " 'financall': (['financially'], 0),\n",
       " 'contanly': (['constantly'], 0),\n",
       " 'wooded': ([], 1),\n",
       " 'acitecture': (['architecture'], 0),\n",
       " 'iluminatd': (['illuminated'], 0),\n",
       " 'bligin': (['obliging'], 0),\n",
       " 'wooden': ([], 17),\n",
       " 'weele': (['wheeler', 'wheeled'], 0),\n",
       " 'creles': (['careless'], 0),\n",
       " 'cmmnded': (['commanded', 'commended'], 0),\n",
       " 'bligig': (['obliging'], 0),\n",
       " 'wednesday': ([], 4),\n",
       " 'trphy': (['trophy'], 0),\n",
       " 'thorughl': (['thoroughly'], 0),\n",
       " 'onopol': (['monopoly'], 0),\n",
       " 'weely': (['weekly', 'sweetly'], 0),\n",
       " 'raitor': (['traitors', 'traitor'], 0),\n",
       " 'plorers': (['explorers'], 0),\n",
       " 'thorughy': (['thoroughly'], 0),\n",
       " 'remaring': (['remarking'], 0),\n",
       " 'weelr': (['wheeler'], 0),\n",
       " 'weels': (['wheels'], 0),\n",
       " 'trsholds': (['thresholds'], 0),\n",
       " 'predegast': (['prendergast'], 0),\n",
       " 'whispring': (['whispering'], 0),\n",
       " 'gladone': (['gladstone'], 0),\n",
       " 'ctatrophe': (['catastrophe'], 0),\n",
       " 'disribue': (['distribute'], 0),\n",
       " 'woodw': (['woodrow'], 0),\n",
       " 'frontna': (['frontenac'], 0),\n",
       " 'frontnc': (['frontenac'], 0),\n",
       " 'dawers': (['drawers'], 0),\n",
       " 'rpsed': (['reposed'], 0),\n",
       " 'udeneath': (['underneath'], 0),\n",
       " 'clnton': (['clinton'], 0),\n",
       " 'episcopte': (['episcopate'], 0),\n",
       " 'disribut': (['distribute'], 0),\n",
       " 'disciplied': (['disciplined'], 0),\n",
       " 'ubverion': (['subversion'], 0),\n",
       " 'mutached': (['moustached'], 0),\n",
       " 'bakrutcy': (['bankruptcy'], 0),\n",
       " 'numerat': (['enumerate'], 0),\n",
       " 'nalysis': (['analysis'], 0),\n",
       " 'emancipt': (['emancipate'], 0),\n",
       " 'snaors': (['senators'], 0),\n",
       " 'bigraphical': (['biographical'], 0),\n",
       " 'berkshie': (['berkshire'], 0),\n",
       " 'itrgues': (['intrigues'], 0),\n",
       " 'ncouteous': (['uncourteous'], 0),\n",
       " 'royaty': (['royalty'], 0),\n",
       " 'reputain': (['reputation'], 0),\n",
       " 'reputaio': (['reputation'], 0),\n",
       " 'numerae': (['enumerate'], 0),\n",
       " 'disapars': (['disappears'], 0),\n",
       " 'bellgrents': (['belligerents'], 0),\n",
       " 'beforehnd': (['beforehand'], 0),\n",
       " 'replaced': ([], 1),\n",
       " 'nostrls': (['nostrils'], 0),\n",
       " 'contrctig': (['contracting'], 0),\n",
       " 'approvig': (['approving'], 0),\n",
       " 'sholhouses': (['schoolhouses'], 0),\n",
       " 'evintly': (['evidently'], 0),\n",
       " 'ulpit': (['culprit', 'pulpit'], 0),\n",
       " 'wasington': (['washington'], 0),\n",
       " 'grzng': (['grazing'], 0),\n",
       " 'faciltate': (['facilitate'], 0),\n",
       " 'emptid': (['emptied'], 0),\n",
       " 'exported': ([], 1),\n",
       " 'abetrs': (['abettors'], 0),\n",
       " 'rotecton': (['protection'], 0),\n",
       " 'circmstancs': (['circumstances'], 0),\n",
       " 'ilnes': (['illness'], 0),\n",
       " 'partclarly': (['particularly'], 0),\n",
       " 'orunes': (['fortunes'], 0),\n",
       " 'legisltin': (['legislation'], 0),\n",
       " 'kids': (['kinds'], 0),\n",
       " 'pemaure': (['premature'], 0),\n",
       " 'rpets': (['carpets'], 0),\n",
       " 'exponded': (['expounded'], 0),\n",
       " 'kidy': (['kindly'], 0),\n",
       " 'deferring': ([], 1),\n",
       " 'aquisce': (['acquiesce'], 0),\n",
       " 'signiicance': (['significance'], 0),\n",
       " 'controversy': ([], 6),\n",
       " 'controverse': (['controversies'], 0),\n",
       " 'provoed': (['provoked'], 0),\n",
       " 'remking': (['remarking'], 0),\n",
       " 'controversa': (['controversial'], 0),\n",
       " 'congraultions': (['congratulations'], 0),\n",
       " 'controversl': (['controversial'], 0),\n",
       " 'kidl': (['kindly'], 0),\n",
       " 'controversi': (['controversial', 'controversies'], 0),\n",
       " 'elgibe': (['eligible'], 0),\n",
       " 'domiane': (['dominance'], 0),\n",
       " 'disretion': (['discretion'], 0),\n",
       " 'elijh': (['elijah'], 0),\n",
       " 'houhtless': (['thoughtless'], 0),\n",
       " 'dallian': (['dalliance'], 0),\n",
       " 'actionbl': (['actionable'], 0),\n",
       " 'elgibl': (['eligible'], 0),\n",
       " 'trvelled': (['travelled'], 0),\n",
       " 'iverpoo': (['liverpool'], 0),\n",
       " 'gardsme': (['guardsmen'], 0),\n",
       " 'ocain': (['cocaine'], 0),\n",
       " 'rifting': (['drifting'], 0),\n",
       " 'imerinent': (['impertinent'], 0),\n",
       " 'aceably': (['peaceably'], 0),\n",
       " 'ocaie': (['cocaine'], 0),\n",
       " 'trvelles': (['travellers'], 0),\n",
       " 'vacuatin': (['evacuation'], 0),\n",
       " 'gardsmn': (['guardsmen'], 0),\n",
       " 'neihor': (['neighbor'], 0),\n",
       " 'ocaic': (['oceanic'], 0),\n",
       " 'dne': (['done', 'dense', 'dane', 'dine', 'deane', 'dined'], 0),\n",
       " 'dnd': (['dined'], 0),\n",
       " 'dng': (['doing', 'dingy', 'dying'], 0),\n",
       " 'astrdam': (['amsterdam'], 0),\n",
       " 'dna': (['donna'], 0),\n",
       " 'tywriter': (['typewriter'], 0),\n",
       " 'btruded': (['obtruded'], 0),\n",
       " 'dnn': (['donna'], 0),\n",
       " 'partisnhip': (['partisanship'], 0),\n",
       " 'fitess': (['fitness'], 0),\n",
       " 'dnk': (['dank', 'drink', 'drank', 'drunk'], 0),\n",
       " 'defaying': (['defraying'], 0),\n",
       " 'luxuous': (['luxurious'], 0),\n",
       " 'dnt': (['dint'], 0),\n",
       " 'asistin': (['assisting'], 0),\n",
       " 'dns': (['dense'], 0),\n",
       " 'violently': ([], 2),\n",
       " 'sidebard': (['sideboard'], 0),\n",
       " 'indlgnt': (['indulgent'], 0),\n",
       " 'dny': (['dingy', 'deny'], 0),\n",
       " 'llustraion': (['illustration'], 0),\n",
       " 'wandrd': (['wandered'], 0),\n",
       " 'wandre': (['wandered'], 0),\n",
       " 'colleaues': (['colleagues'], 0),\n",
       " 'tader': (['traders'], 0),\n",
       " 'stuios': (['studious'], 0),\n",
       " 'stuiou': (['studious'], 0),\n",
       " 'ructantly': (['reluctantly'], 0),\n",
       " 'populations': ([], 4),\n",
       " 'auckad': (['auckland'], 0),\n",
       " 'disapprvd': (['disapproved'], 0),\n",
       " 'oonization': (['colonization'], 0),\n",
       " 'bcurity': (['obscurity'], 0),\n",
       " 'frtuate': (['fortunate'], 0),\n",
       " 'elsti': (['elastic'], 0),\n",
       " 'toeraed': (['tolerated'], 0),\n",
       " 'aprecated': (['appreciated'], 0),\n",
       " 'landestne': (['clandestine'], 0),\n",
       " 'aisfied': (['satisfied'], 0),\n",
       " 'pariaent': (['parliament'], 0),\n",
       " 'pzle': (['puzzle'], 0),\n",
       " 'rprising': (['surprising'], 0),\n",
       " 'questionale': (['questionable'], 0),\n",
       " 'iventries': (['inventories'], 0),\n",
       " 'asnishment': (['astonishment'], 0),\n",
       " 'deletes': (['delegates'], 0),\n",
       " 'listenin': (['listening'], 0),\n",
       " 'cofeerates': (['confederates'], 0),\n",
       " 'desirabilty': (['desirability'], 0),\n",
       " 'ninite': (['infinite'], 0),\n",
       " 'homeseads': (['homesteads'], 0),\n",
       " 'calsad': (['carlsbad'], 0),\n",
       " 'paraoxial': (['paradoxical'], 0),\n",
       " 'mecenaries': (['mercenaries'], 0),\n",
       " 'listenig': (['listening'], 0),\n",
       " 'flouried': (['flourished'], 0),\n",
       " 'teutnic': (['teutonic'], 0),\n",
       " 'epoyee': (['employee'], 0),\n",
       " 'accumuation': (['accumulation'], 0),\n",
       " 'reiprocl': (['reciprocal'], 0),\n",
       " 'orinality': (['originality'], 0),\n",
       " 'undetake': (['undertake', 'undertaken'], 0),\n",
       " 'boough': (['boroughs'], 0),\n",
       " 'sectarianism': ([], 1),\n",
       " 'outloo': (['outlook'], 0),\n",
       " 'beforhand': (['beforehand'], 0),\n",
       " 'pints': (['points', 'prints'], 0),\n",
       " 'imperlle': (['imperilled'], 0),\n",
       " 'repies': (['replies'], 0),\n",
       " 'pintd': (['printed', 'pointed', 'painted'], 0),\n",
       " 'pinte': (['printed', 'pointed', 'painted', 'printer'], 0),\n",
       " 'oppessvely': (['oppressively'], 0),\n",
       " 'rudulent': (['fraudulent'], 0),\n",
       " 'flwng': (['flowing'], 0),\n",
       " 'repied': (['replied'], 0),\n",
       " 'signfiance': (['significance'], 0),\n",
       " 'meryweathe': (['merryweather'], 0),\n",
       " 'foppishess': (['foppishness'], 0),\n",
       " 'klhoma': (['oklahoma'], 0),\n",
       " 'injurus': (['injurious'], 0),\n",
       " 'fmhouses': (['farmhouses'], 0),\n",
       " 'searhng': (['searching'], 0),\n",
       " 'hievs': (['thieves'], 0),\n",
       " 'juncre': (['juncture'], 0),\n",
       " 'nformlity': (['informality'], 0),\n",
       " 'cllar': (['collar', 'cellar'], 0),\n",
       " 'motionlss': (['motionless'], 0),\n",
       " 'insearabe': (['inseparable'], 0),\n",
       " 'exelent': (['excellent'], 0),\n",
       " 'llant': (['gallant'], 0),\n",
       " 'meryweathr': (['merryweather'], 0),\n",
       " 'unintended': ([], 1),\n",
       " 'tederess': (['tenderness'], 0),\n",
       " 'eormous': (['enormous'], 0),\n",
       " 'ioet': (['violet'], 0),\n",
       " 'hieve': (['thieves'], 0),\n",
       " 'beyed': (['obeyed'], 0),\n",
       " 'cogreses': (['congresses'], 0),\n",
       " 'barbrc': (['barbaric'], 0),\n",
       " 'distintion': (['distinction'], 0),\n",
       " 'aprovingly': (['approvingly'], 0),\n",
       " 'sceenin': (['screening'], 0),\n",
       " 'poeic': (['poetic'], 0),\n",
       " 'ombattd': (['combatted'], 0),\n",
       " 'dssolut': (['dissolute'], 0),\n",
       " 'ubured': (['unburned'], 0),\n",
       " 'barbri': (['barbaric'], 0),\n",
       " 'sceenig': (['screening'], 0),\n",
       " 'suppsin': (['supposing'], 0),\n",
       " 'wrone': (['wronged'], 0),\n",
       " 'wrond': (['wronged'], 0),\n",
       " 'wrong': (['wronged'], 18),\n",
       " 'dssolue': (['dissolute'], 0),\n",
       " 'mongomey': (['montgomery'], 0),\n",
       " 'indepedntly': (['independently'], 0),\n",
       " 'cvention': (['convention'], 0),\n",
       " 'insearabl': (['inseparable'], 0),\n",
       " 'eauies': (['beauties'], 0),\n",
       " 'cmunicative': (['communicative'], 0),\n",
       " 'prejudies': (['prejudices'], 0),\n",
       " 'gafiters': (['gasfitters'], 0),\n",
       " 'springng': (['springing'], 0),\n",
       " 'inviolt': (['inviolate'], 0),\n",
       " 'classi': (['classic'], 0),\n",
       " 'wgmoe': (['wigmore'], 0),\n",
       " 'frintosh': (['farintosh'], 0),\n",
       " 'emloymen': (['employment'], 0),\n",
       " 'regste': (['register'], 0),\n",
       " 'marquett': (['marquette'], 0),\n",
       " 'revsal': (['reversal'], 0),\n",
       " 'bockades': (['blockades'], 0),\n",
       " 'regsty': (['registry'], 0),\n",
       " 'inviola': (['inviolate'], 0),\n",
       " 'ccontant': (['accountant'], 0),\n",
       " 'conquero': (['conqueror', 'conquerors'], 0),\n",
       " 'inviole': (['inviolate'], 0),\n",
       " 'regstr': (['registry', 'register'], 0),\n",
       " 'oganzations': (['organizations'], 0),\n",
       " 'essin': (['session', 'cession'], 0),\n",
       " 'wgmor': (['wigmore'], 0),\n",
       " 'marquete': (['marquette'], 0),\n",
       " 'flused': (['flushed'], 0),\n",
       " 'sppresing': (['suppressing'], 0),\n",
       " 'elewhre': (['elsewhere'], 0),\n",
       " 'atualy': (['actually'], 0),\n",
       " 'ousoken': (['outspoken'], 0),\n",
       " 'negbor': (['neighbor'], 0),\n",
       " 'weken': (['weaken'], 0),\n",
       " 'welcomed': ([], 3),\n",
       " 'forear': (['forearm'], 0),\n",
       " 'mercandse': (['merchandise'], 0),\n",
       " 'foreaw': (['foresaw'], 0),\n",
       " 'weked': (['wrecked'], 0),\n",
       " 'engrossed': ([], 2),\n",
       " 'wehty': (['weighty'], 0),\n",
       " 'isputd': (['disputed'], 0),\n",
       " 'mdeation': (['moderation'], 0),\n",
       " 'forean': (['foreman'], 0),\n",
       " 'foream': (['forearm'], 0),\n",
       " 'atuall': (['actually'], 0),\n",
       " 'brihly': (['brightly'], 0),\n",
       " 'inscruabe': (['inscrutable'], 0),\n",
       " 'poplaity': (['popularity'], 0),\n",
       " 'cyer': (['clymer'], 0),\n",
       " 'foread': (['forehead'], 0),\n",
       " 'fir': (['first',\n",
       "   'fire',\n",
       "   'fiery',\n",
       "   'firm',\n",
       "   'fair',\n",
       "   'fiver',\n",
       "   'finer',\n",
       "   'fired',\n",
       "   'fires',\n",
       "   'flair'],\n",
       "  2),\n",
       " 'fis': (['first',\n",
       "   'finds',\n",
       "   'fills',\n",
       "   'fists',\n",
       "   'fish',\n",
       "   'fits',\n",
       "   'flies',\n",
       "   'files',\n",
       "   'finns',\n",
       "   'fines',\n",
       "   'fiske',\n",
       "   'fires',\n",
       "   'fixes'],\n",
       "  0),\n",
       " 'suprvised': (['supervised'], 0),\n",
       " 'fiv': (['five', 'fiver'], 0),\n",
       " 'ngoverable': (['ungovernable'], 0),\n",
       " 'fit': (['first',\n",
       "   'fifty',\n",
       "   'fists',\n",
       "   'fight',\n",
       "   'faith',\n",
       "   'fifth',\n",
       "   'fits',\n",
       "   'faint',\n",
       "   'fritz',\n",
       "   'fait',\n",
       "   'flint'],\n",
       "  10),\n",
       " 'fiz': (['hafiz', 'fritz'], 0),\n",
       " 'screaming': ([], 2),\n",
       " 'fix': (['fixed', 'felix', 'fixes'], 3),\n",
       " 'fiy': (['fifty', 'fiery'], 0),\n",
       " 'excheqe': (['exchequer'], 0),\n",
       " 'ameriaization': (['americanization'], 0),\n",
       " 'laitude': (['lassitude'], 0),\n",
       " 'cnde': (['candle', 'cinder'], 0),\n",
       " 'cndd': (['candid'], 0),\n",
       " 'fif': (['fifty', 'fifth'], 0),\n",
       " 'fig': (['fight'], 0),\n",
       " 'fid': (['find', 'finds', 'field', 'fixed', 'filed', 'fined', 'fired'], 0),\n",
       " 'fie': (['file',\n",
       "   'fire',\n",
       "   'five',\n",
       "   'field',\n",
       "   'fine',\n",
       "   'fiery',\n",
       "   'fixed',\n",
       "   'flies',\n",
       "   'files',\n",
       "   'fiver',\n",
       "   'filed',\n",
       "   'finer',\n",
       "   'foie',\n",
       "   'fined',\n",
       "   'fines',\n",
       "   'fiske',\n",
       "   'fired',\n",
       "   'fires',\n",
       "   'fixes'],\n",
       "  0),\n",
       " 'peparation': (['preparations', 'preparation'], 0),\n",
       " 'fih': (['fish', 'fight', 'faith', 'fifth'], 0),\n",
       " 'infomaity': (['informality'], 0),\n",
       " 'fin': (['find',\n",
       "   'finds',\n",
       "   'fine',\n",
       "   'final',\n",
       "   'finns',\n",
       "   'faint',\n",
       "   'fain',\n",
       "   'finer',\n",
       "   'fined',\n",
       "   'fines',\n",
       "   'flint'],\n",
       "  0),\n",
       " 'fghnistan': (['afghanistan'], 0),\n",
       " 'fil': (['file',\n",
       "   'fail',\n",
       "   'fills',\n",
       "   'field',\n",
       "   'fill',\n",
       "   'foil',\n",
       "   'final',\n",
       "   'files',\n",
       "   'filed',\n",
       "   'frill',\n",
       "   'frail'],\n",
       "  0),\n",
       " 'fim': (['firm'], 0),\n",
       " 'foolih': (['foolish'], 0),\n",
       " 'pausible': (['plausible'], 0),\n",
       " 'slemny': (['solemnly'], 0),\n",
       " 'ahinery': (['machinery'], 0),\n",
       " 'rdrobe': (['wardrobe'], 0),\n",
       " 'heere': (['cheered'], 0),\n",
       " 'specfially': (['specifically'], 0),\n",
       " 'pologize': (['apologize'], 0),\n",
       " 'olunteer': (['volunteers'], 0),\n",
       " 'indvidualit': (['individuality'], 0),\n",
       " 'qarrls': (['quarrels'], 0),\n",
       " 'dsite': (['despite'], 0),\n",
       " 'ecyclopaedas': (['encyclopaedias'], 0),\n",
       " 'foolis': (['foolish'], 0),\n",
       " 'uarrellin': (['quarrelling'], 0),\n",
       " 'sovd': (['solved'], 0),\n",
       " 'sove': (['solved', 'solve', 'shoves', 'strove'], 0),\n",
       " 'moality': (['morality'], 0),\n",
       " 'slemnl': (['solemnly'], 0),\n",
       " 'upaered': (['unpapered'], 0),\n",
       " 'thanksgvin': (['thanksgiving'], 0),\n",
       " 'begnnin': (['beginning'], 0),\n",
       " 'circulaion': (['circulation'], 0),\n",
       " 'olmon': (['solomon'], 0),\n",
       " 'aadons': (['abandons'], 0),\n",
       " 'barton': ([], 1),\n",
       " 'frewel': (['farewell'], 0),\n",
       " 'eronally': (['personally'], 0),\n",
       " 'slttng': (['slitting'], 0),\n",
       " 'temet': (['tempest'], 0),\n",
       " 'jeced': (['ejected'], 0),\n",
       " 'eowered': (['empowered'], 0),\n",
       " 'ailrods': (['railroads'], 0),\n",
       " 'shding': (['shading', 'shedding'], 0),\n",
       " 'uttned': (['buttoned'], 0),\n",
       " 'innumerabe': (['innumerable'], 0),\n",
       " 'desoation': (['desolation'], 0),\n",
       " 'thankgiing': (['thanksgiving'], 0),\n",
       " 'eactng': (['exacting'], 0),\n",
       " 'resposibiity': (['responsibility'], 0),\n",
       " 'acopanied': (['accompanied'], 0),\n",
       " 'childen': (['children'], 0),\n",
       " 'comprises': (['compromises'], 0),\n",
       " 'emigted': (['emigrated'], 0),\n",
       " 'hadest': (['hardest'], 0),\n",
       " 'plattsbrg': (['plattsburgh'], 0),\n",
       " 'reistation': (['registration'], 0),\n",
       " 'unelect': (['unelected'], 0),\n",
       " 'ecitable': (['excitable'], 0),\n",
       " 'kown': (['known'], 0),\n",
       " 'missionries': (['missionaries'], 0),\n",
       " 'carpeers': (['carpenters'], 0),\n",
       " 'golen': (['golden'], 0),\n",
       " 'idmnify': (['indemnify'], 0),\n",
       " 'ummaril': (['summarily'], 0),\n",
       " 'sesationalsm': (['sensationalism'], 0),\n",
       " 'ancstos': (['ancestors'], 0),\n",
       " 'kirmihes': (['skirmishes'], 0),\n",
       " 'colonist': (['colonists'], 0),\n",
       " 'humber': (['humbler'], 0),\n",
       " 'difficuies': (['difficulties'], 0),\n",
       " 'ummarie': (['summarise', 'summarize'], 0),\n",
       " 'ummariz': (['summarize'], 0),\n",
       " 'ummariy': (['summarily'], 0),\n",
       " 'incaculable': (['incalculable'], 0),\n",
       " 'holsale': (['wholesale'], 0),\n",
       " 'ouhly': (['roughly'], 0),\n",
       " 'arrged': (['arranged'], 0),\n",
       " 'fooed': (['flooded'], 0),\n",
       " 'mayfler': (['mayflower'], 0),\n",
       " 'libilites': (['liabilities'], 0),\n",
       " 'dshonouable': (['dishonourable'], 0),\n",
       " 'ugovernble': (['ungovernable'], 0),\n",
       " 'staiin': (['staining'], 0),\n",
       " 'oveloking': (['overlooking'], 0),\n",
       " 'abbots': ([], 1),\n",
       " 'rmembr': (['remember'], 0),\n",
       " 'perseveanc': (['perseverance'], 0),\n",
       " 'staiig': (['staining'], 0),\n",
       " 'nloking': (['unlocking'], 0),\n",
       " 'instructis': (['instructions'], 0),\n",
       " 'perseveane': (['perseverance'], 0),\n",
       " 'peipitated': (['precipitated'], 0),\n",
       " 'rmembe': (['remember'], 0),\n",
       " 'instructin': (['instructions', 'instruction'], 0),\n",
       " 'oances': (['romances'], 0),\n",
       " 'consultaons': (['consultations'], 0),\n",
       " 'nlargin': (['enlarging'], 0),\n",
       " 'instructie': (['instructive'], 0),\n",
       " 'syl': (['style'], 0),\n",
       " 'transformain': (['transformation'], 0),\n",
       " 'osesibly': (['ostensibly'], 0),\n",
       " 'humilaing': (['humiliating'], 0),\n",
       " 'husbands': ([], 1),\n",
       " 'posning': (['poisoning'], 0),\n",
       " 'curchs': (['churches'], 0),\n",
       " 'tepfther': (['stepfather'], 0),\n",
       " 'humbed': (['humbled'], 0),\n",
       " 'ailures': (['failures'], 0),\n",
       " 'mosphere': (['atmosphere'], 0),\n",
       " 'liied': (['limited'], 0),\n",
       " 'absolved': ([], 1),\n",
       " 'expdien': (['expedient'], 0),\n",
       " 'curche': (['churches'], 0),\n",
       " 'crailed': (['curtailed'], 0),\n",
       " 'expdiet': (['expedient'], 0),\n",
       " 'sugestieness': (['suggestiveness'], 0),\n",
       " 'arsbad': (['carlsbad'], 0),\n",
       " 'paphleteers': (['pamphleteers'], 0),\n",
       " 'pisod': (['episode'], 0),\n",
       " 'shipblding': (['shipbuilding'], 0),\n",
       " 'itineant': (['itinerant'], 0),\n",
       " 'ourslvs': (['ourselves'], 0),\n",
       " 'lirares': (['libraries'], 0),\n",
       " 'presints': (['presidents'], 0),\n",
       " 'iseable': (['miserable'], 0),\n",
       " 'ideendently': (['independently'], 0),\n",
       " 'pblem': (['problem'], 0),\n",
       " 'sfter': (['softer'], 0),\n",
       " 'maddnng': (['maddening'], 0),\n",
       " 'obseran': (['observant'], 0),\n",
       " 'conclive': (['conclusive'], 0),\n",
       " 'whsing': (['whishing'], 0),\n",
       " 'amoet': (['samoset'], 0),\n",
       " 'considraion': (['consideration'], 0),\n",
       " 'prsidential': (['presidential'], 0),\n",
       " 'ssurely': (['assuredly'], 0),\n",
       " 'ourslve': (['ourselves'], 0),\n",
       " 'tumet': (['trumpet'], 0),\n",
       " 'xpresed': (['expressed'], 0),\n",
       " 'emigratin': (['emigration'], 0),\n",
       " 'looot': (['lookout'], 0),\n",
       " 'looou': (['lookout'], 0),\n",
       " 'households': ([], 1),\n",
       " 'ydrocloric': (['hydrochloric'], 0),\n",
       " 'oldr': (['older', 'holder', 'solder'], 0),\n",
       " 'oldt': (['oldest'], 0),\n",
       " 'adyhip': (['ladyship'], 0),\n",
       " 'oldy': (['coldly', 'boldly'], 0),\n",
       " 'pisol': (['pistol'], 0),\n",
       " 'mastel': (['masterly'], 0),\n",
       " 'anufactue': (['manufacture'], 0),\n",
       " 'mproisations': (['improvisations'], 0),\n",
       " 'nxius': (['anxious'], 0),\n",
       " 'confliting': (['conflicting'], 0),\n",
       " 'needed': (['unheeded'], 10),\n",
       " 'reecton': (['rejection'], 0),\n",
       " 'endng': (['rending', 'ending', 'bending', 'pending', 'sending', 'endings'],\n",
       "  0),\n",
       " 'master': (['masterly', 'mastery', 'masters'], 22),\n",
       " 'mainteance': (['maintenance'], 0),\n",
       " 'accomoations': (['accommodations'], 0),\n",
       " 'oldl': (['coldly', 'boldly'], 0),\n",
       " 'oloon': (['solomon'], 0),\n",
       " 'mastey': (['masterly', 'mastery'], 0),\n",
       " 'pralel': (['parallel'], 0),\n",
       " 'ocerns': (['concerns'], 0),\n",
       " 'nrtern': (['northern'], 0),\n",
       " 'recsidered': (['reconsidered'], 0),\n",
       " 'cmpomises': (['compromises'], 0),\n",
       " 'farinoh': (['farintosh'], 0),\n",
       " 'ortimer': (['mortimer'], 0),\n",
       " 'unnserable': (['unanswerable'], 0),\n",
       " 'nobilty': (['nobility'], 0),\n",
       " 'esying': (['essaying'], 0),\n",
       " 'diticts': (['districts'], 0),\n",
       " 'cnsciou': (['conscious'], 0),\n",
       " 'farinos': (['farintosh'], 0),\n",
       " 'cnscios': (['conscious'], 0),\n",
       " 'ratfyin': (['ratifying'], 0),\n",
       " 'psies': (['gipsies'], 0),\n",
       " 'inducments': (['inducements'], 0),\n",
       " 'positively': ([], 2),\n",
       " 'prales': (['parables'], 0),\n",
       " 'shperd': (['shepherd'], 0),\n",
       " 'ahmed': (['ashamed'], 0),\n",
       " 'fstvities': (['festivities'], 0),\n",
       " 'squatts': (['squatters'], 0),\n",
       " 'cosolidation': (['consolidation'], 0),\n",
       " 'prducin': (['producing'], 0),\n",
       " 'eaest': (['earnest', 'nearest', 'dearest', 'easiest'], 0),\n",
       " 'litgnts': (['litigants'], 0),\n",
       " 'eeditary': (['hereditary'], 0),\n",
       " 'ndias': (['indians'], 0),\n",
       " 'ndial': (['sundial'], 0),\n",
       " 'trespaer': (['trespasser'], 0),\n",
       " 'exclaimed': ([], 17),\n",
       " 'friend': (['friends', 'friendly'], 89),\n",
       " 'unexpeted': (['unexpected'], 0),\n",
       " 'roterdam': (['rotterdam'], 0),\n",
       " 'cnniance': (['connivance'], 0),\n",
       " 'ndiaa': (['indiana'], 0),\n",
       " 'reoutions': (['resolutions', 'revolutions'], 0),\n",
       " 'comproisng': (['compromising'], 0),\n",
       " 'hson': (['hudson'], 0),\n",
       " 'xposition': (['exposition'], 0),\n",
       " 'hsom': (['hansom'], 0),\n",
       " 'laied': (['claimed'], 0),\n",
       " 'chaacterized': (['characterized'], 0),\n",
       " 'litchfed': (['litchfield'], 0),\n",
       " 'heper': (['helper'], 0),\n",
       " 'wandred': (['wandered'], 0),\n",
       " 'reurn': (['returns', 'return'], 0),\n",
       " 'isecs': (['insects'], 0),\n",
       " 'seacost': (['seacoast'], 0),\n",
       " 'consttutinal': (['constitutional'], 0),\n",
       " 'ecptive': (['deceptive'], 0),\n",
       " 'bogat': (['bogart'], 0),\n",
       " 'unters': (['hunters'], 0),\n",
       " 'heped': (['helped', 'heaped'], 0),\n",
       " 'laier': (['plainer'], 0),\n",
       " 'laies': (['ladies'], 0),\n",
       " 'reurs': (['returns'], 0),\n",
       " 'whtington': (['whittington'], 0),\n",
       " 'nvces': (['novices'], 0),\n",
       " 'attinmnts': (['attainments'], 0),\n",
       " 'conessed': (['confessed'], 0),\n",
       " 'expansn': (['expansion'], 0),\n",
       " 'relves': (['resolves'], 0),\n",
       " 'congresen': (['congressmen'], 0),\n",
       " 'xplred': (['explored'], 0),\n",
       " 'qukers': (['quakers'], 0),\n",
       " 'wandrer': (['wanderers'], 0),\n",
       " 'wandres': (['wanderers'], 0),\n",
       " 'poessions': (['possessions', 'professions'], 0),\n",
       " 'sitin': (['sitting'], 0),\n",
       " 'msssoit': (['massasoit'], 0),\n",
       " 'mysteiou': (['mysterious'], 0),\n",
       " 'panllng': (['panelling'], 0),\n",
       " 'footths': (['footpaths'], 0),\n",
       " 'sitig': (['sitting'], 0),\n",
       " 'isappearing': (['disappearing'], 0),\n",
       " 'mysteios': (['mysterious'], 0),\n",
       " 'dsregaring': (['disregarding'], 0),\n",
       " 'cntrst': (['contrast'], 0),\n",
       " 'expoulating': (['expostulating'], 0),\n",
       " 'sacstically': (['sarcastically'], 0),\n",
       " 'explied': (['explained'], 0),\n",
       " 'cnfederaton': (['confederation'], 0),\n",
       " 'maonald': (['macdonald'], 0),\n",
       " 'mothrland': (['motherland'], 0),\n",
       " 'erfidiousness': (['perfidiousness'], 0),\n",
       " 'surassng': (['surpassing'], 0),\n",
       " 'genuity': (['ingenuity'], 0),\n",
       " 'unknow': (['unknown'], 0),\n",
       " 'dailed': (['detailed'], 0),\n",
       " 'agremnts': (['agreements'], 0),\n",
       " 'cosierable': (['considerable'], 0),\n",
       " 'relctane': (['reluctance'], 0),\n",
       " 'paradxical': (['paradoxical'], 0),\n",
       " 'relctanc': (['reluctance'], 0),\n",
       " 'depedecy': (['dependency'], 0),\n",
       " 'coneuences': (['consequences'], 0),\n",
       " 'authortatve': (['authoritative'], 0),\n",
       " 'cosierably': (['considerably'], 0),\n",
       " 'carcty': (['scarcity'], 0),\n",
       " 'ndistinguishable': (['indistinguishable'], 0),\n",
       " 'ipeachmet': (['impeachment'], 0),\n",
       " 'precisly': (['precisely'], 0),\n",
       " 'branywine': (['brandywine'], 0),\n",
       " 'clibed': (['climbed'], 0),\n",
       " 'unknon': (['unknown'], 0),\n",
       " 'bsolutim': (['absolutism'], 0),\n",
       " 'majo': (['major'], 0),\n",
       " 'inriguin': (['intriguing'], 0),\n",
       " 'coparatve': (['comparative'], 0),\n",
       " 'sidelng': (['sidelong'], 0),\n",
       " 'treuries': (['treasuries'], 0),\n",
       " 'squatti': (['squatting'], 0),\n",
       " 'precipiaed': (['precipitated'], 0),\n",
       " 'magcian': (['magician'], 0),\n",
       " 'willingy': (['willingly'], 0),\n",
       " 'maeilles': (['marseilles'], 0),\n",
       " 'prorietary': (['proprietary'], 0),\n",
       " 'tech': (['teach'], 0),\n",
       " 'fugitives': ([], 1),\n",
       " 'odified': (['modified'], 0),\n",
       " 'willingl': (['willingly'], 0),\n",
       " 'sqeeed': (['squeezed'], 0),\n",
       " 'methyst': (['amethyst'], 0),\n",
       " 'majr': (['major'], 0),\n",
       " 'cleica': (['clerical'], 0),\n",
       " 'uhinkable': (['unthinkable'], 0),\n",
       " 'disconet': (['discontent'], 0),\n",
       " 'retring': (['returning', 'retiring', 'restoring', 'retracing'], 0),\n",
       " 'disikin': (['disliking'], 0),\n",
       " 'impicaes': (['implicates'], 0),\n",
       " 'etonville': (['pentonville'], 0),\n",
       " 'whisng': (['whishing'], 0),\n",
       " 'impicaed': (['implicated'], 0),\n",
       " 'bseeching': (['beseeching'], 0),\n",
       " 'psperity': (['prosperity'], 0),\n",
       " 'retrint': (['restraint'], 0),\n",
       " 'disconen': (['discontent'], 0),\n",
       " 'tempted': (['attempted'], 1),\n",
       " 'rearaging': (['rearranging'], 0),\n",
       " 'unconstiutional': (['unconstitutional'], 0),\n",
       " 'abyrinth': (['labyrinth'], 0),\n",
       " 'orolk': (['norfolk'], 0),\n",
       " 'apace': (['apache', 'apaches'], 0),\n",
       " 'crosities': (['curiosities'], 0),\n",
       " 'ntrustd': (['intrusted', 'entrusted'], 0),\n",
       " 'lubs': (['clubs'], 0),\n",
       " 'omplimnted': (['complimented'], 0),\n",
       " 'pitful': (['pitiful'], 0),\n",
       " 'iscovry': (['discovery'], 0),\n",
       " 'rglating': (['regulating'], 0),\n",
       " 'apach': (['apache', 'apaches'], 0),\n",
       " 'osisting': (['consisting'], 0),\n",
       " 'dolar': (['dollars', 'dollar'], 0),\n",
       " 'lube': (['lumber'], 0),\n",
       " 'puisment': (['punishment'], 0),\n",
       " 'pesnal': (['personal'], 0),\n",
       " 'suneam': (['sunbeam'], 0),\n",
       " 'batill': (['bastille'], 0),\n",
       " 'lusous': (['lustrous'], 0),\n",
       " 'mttleome': (['mettlesome'], 0),\n",
       " 'hodrs': (['holders'], 0),\n",
       " 'enouragemnt': (['encouragement'], 0),\n",
       " 'xportaton': (['exportation'], 0),\n",
       " 'paiets': (['patients'], 0),\n",
       " 'haraterises': (['characterises'], 0),\n",
       " 'disset': (['dissent'], 0),\n",
       " 'iate': (['dilate', 'innate'], 0),\n",
       " 'crrntly': (['currently'], 0),\n",
       " 'paietl': (['parietal'], 0),\n",
       " 'uncocened': (['unconcerned'], 0),\n",
       " 'paieta': (['parietal'], 0),\n",
       " 'lchfield': (['litchfield'], 0),\n",
       " 'amchars': (['armchairs'], 0),\n",
       " 'tmpation': (['temptation'], 0),\n",
       " 'revkd': (['revoked'], 0),\n",
       " 'patce': (['patches'], 0),\n",
       " 'xfrdshire': (['oxfordshire'], 0),\n",
       " 'monrhical': (['monarchical'], 0),\n",
       " 'exposulting': (['expostulating'], 0),\n",
       " 'idisceetly': (['indiscreetly'], 0),\n",
       " 'patck': (['patrick'], 0),\n",
       " 'norhwestely': (['northwesterly'], 0),\n",
       " 'seaated': (['separated'], 0),\n",
       " 'patch': (['patches'], 1),\n",
       " 'lunched': (['launched'], 0),\n",
       " 'chaleson': (['charleston'], 0),\n",
       " 'adrers': (['admirers'], 0),\n",
       " 'patcs': (['patches'], 0),\n",
       " 'colodo': (['colorado'], 0),\n",
       " 'teptaton': (['temptation'], 0),\n",
       " 'ommuniate': (['communicate'], 0),\n",
       " 'abnormll': (['abnormally'], 0),\n",
       " 'csply': (['crisply'], 0),\n",
       " 'etil': (['detail', 'retail'], 0),\n",
       " 'conant': (['covenant', 'constant'], 0),\n",
       " 'rihess': (['richness'], 0),\n",
       " 'withraal': (['withdrawal'], 0),\n",
       " 'aspration': (['aspirations'], 0),\n",
       " 'rihest': (['richest'], 0),\n",
       " 'conans': (['contains'], 0),\n",
       " 'urredering': (['surrendering'], 0),\n",
       " 'ltterie': (['lotteries'], 0),\n",
       " 'etie': (['metier', 'retire', 'entire'], 0),\n",
       " 'fotarks': (['footmarks'], 0),\n",
       " 'eenings': (['evenings'], 0),\n",
       " 'simlicty': (['simplicity'], 0),\n",
       " 'etic': (['poetic', 'celtic'], 0),\n",
       " 'counries': (['countries'], 0),\n",
       " 'cmmunl': (['communal'], 0),\n",
       " 'magnifent': (['magnificent'], 0),\n",
       " 'smpathiers': (['sympathizers'], 0),\n",
       " 'oninuing': (['continuing'], 0),\n",
       " 'etir': (['metier', 'retire', 'entire'], 0),\n",
       " 'carciy': (['scarcity'], 0),\n",
       " 'iry': (['fiery', 'dirty', 'diary', 'ivory', 'wiry', 'irony'], 0),\n",
       " 'ordsman': (['swordsman'], 0),\n",
       " 'desiabe': (['desirable'], 0),\n",
       " 'conrbution': (['contribution'], 0),\n",
       " 'irs': (['first',\n",
       "   'irish',\n",
       "   'birds',\n",
       "   'heirs',\n",
       "   'girls',\n",
       "   'virus',\n",
       "   'pairs',\n",
       "   'fires'],\n",
       "  0),\n",
       " 'irt': (['first', 'dirty', 'girt', 'skirt', 'shirt', 'dirt', 'wirt'], 0),\n",
       " 'iru': (['virus'], 0),\n",
       " 'malower': (['mayflower'], 0),\n",
       " 'toastmaste': (['toastmaster'], 0),\n",
       " 'irh': (['irish'], 0),\n",
       " 'iri': (['irish'], 0),\n",
       " 'ousing': (['arousing', 'rousing'], 0),\n",
       " 'irl': (['girl', 'girls'], 0),\n",
       " 'irm': (['firm'], 0),\n",
       " 'irn': (['irene', 'iron', 'irony'], 0),\n",
       " 'iro': (['iron', 'irony'], 0),\n",
       " 'colest': (['coolest'], 0),\n",
       " 'ira': (['tiara'], 0),\n",
       " 'opeaed': (['operated'], 0),\n",
       " 'ird': (['bird',\n",
       "   'third',\n",
       "   'weird',\n",
       "   'wired',\n",
       "   'birds',\n",
       "   'hired',\n",
       "   'tired',\n",
       "   'fired'],\n",
       "  0),\n",
       " 'ire': (['irene',\n",
       "   'fire',\n",
       "   'wire',\n",
       "   'wired',\n",
       "   'tire',\n",
       "   'hired',\n",
       "   'tired',\n",
       "   'fired',\n",
       "   'fires',\n",
       "   'quire',\n",
       "   'dire'],\n",
       "  1),\n",
       " 'coless': (['coolness', 'coldness'], 0),\n",
       " 'wage': (['wages', 'wager', 'waged'], 2),\n",
       " 'oarsel': (['hoarsely', 'coarsely'], 0),\n",
       " 'natura': (['natural'], 0),\n",
       " 'inanciall': (['financially'], 0),\n",
       " 'brasts': (['breasts'], 0),\n",
       " 'extend': (['extended'], 3),\n",
       " 'nature': (['natured', 'natures'], 40),\n",
       " 'thorouness': (['thoroughness'], 0),\n",
       " 'cultivaion': (['cultivation'], 0),\n",
       " 'naturl': (['natural'], 0),\n",
       " 'naturs': (['natures'], 0),\n",
       " 'pampleter': (['pamphleteer'], 0),\n",
       " 'inconsequntal': (['inconsequential'], 0),\n",
       " 'deficencis': (['deficiencies'], 0),\n",
       " 'extent': ([], 8),\n",
       " 'coecy': (['cogency'], 0),\n",
       " 'dwload': (['download'], 0),\n",
       " 'eqest': (['bequest', 'request'], 0),\n",
       " 'coniing': (['confining'], 0),\n",
       " 'thickein': (['thickening'], 0),\n",
       " 'sleut': (['sleuth'], 0),\n",
       " 'bnner': (['banner'], 0),\n",
       " 'bnnet': (['bonnet'], 0),\n",
       " 'diploatic': (['diplomatic'], 0),\n",
       " 'roessing': (['processing', 'professing'], 0),\n",
       " 'njustie': (['injustice'], 0),\n",
       " 'reonized': (['recognized'], 0),\n",
       " 'njustic': (['injustice'], 0),\n",
       " 'jwelley': (['jewellery'], 0),\n",
       " 'shipyars': (['shipyards'], 0),\n",
       " 'jweller': (['jewellery', 'jeweller'], 0),\n",
       " 'eceptons': (['exceptions'], 0),\n",
       " 'retrogresso': (['retrogression'], 0),\n",
       " 'retrogressn': (['retrogression'], 0),\n",
       " 'sleuh': (['sleuth'], 0),\n",
       " 'straghtned': (['straightened'], 0),\n",
       " 'wagn': (['wagons', 'wagon', 'waging'], 0),\n",
       " 'foreclosing': ([], 1),\n",
       " 'mgratio': (['migration'], 0),\n",
       " 'mgratin': (['migration'], 0),\n",
       " 'superscied': (['superscribed'], 0),\n",
       " 'decends': (['descends'], 0),\n",
       " 'xhaus': (['exhaust'], 0),\n",
       " 'cofisction': (['confiscation'], 0),\n",
       " 'grauall': (['gradually'], 0),\n",
       " 'crdior': (['creditor'], 0),\n",
       " 'poplaion': (['population'], 0),\n",
       " 'nsoms': (['hansoms'], 0),\n",
       " 'preciitaing': (['precipitating'], 0),\n",
       " 'traller': (['traveller'], 0),\n",
       " 'graualy': (['gradually'], 0),\n",
       " 'froed': (['frogged', 'frosted'], 0),\n",
       " 'humming': ([], 2),\n",
       " 'decendd': (['descended'], 0),\n",
       " 'decende': (['descended'], 0),\n",
       " 'orgnizing': (['organizing'], 0),\n",
       " 'plnkng': (['planking'], 0),\n",
       " 'intuitis': (['intuitions'], 0),\n",
       " 'angel': ([], 21),\n",
       " 'mnacd': (['menaced'], 0),\n",
       " 'mnace': (['menaced', 'menace'], 0),\n",
       " 'mnach': (['monarch'], 0),\n",
       " 'continousy': (['continuously'], 0),\n",
       " 'expecanies': (['expectancies'], 0),\n",
       " 'greemen': (['agreement'], 0),\n",
       " 'virtally': (['virtually'], 0),\n",
       " 'exprations': (['explorations'], 0),\n",
       " 'oubreaks': (['outbreaks'], 0),\n",
       " 'intuitin': (['intuition', 'intuitions'], 0),\n",
       " 'intuitio': (['intuition', 'intuitions'], 0),\n",
       " 'opefu': (['hopeful'], 0),\n",
       " 'obese': ([], 1),\n",
       " 'heps': (['helps'], 0),\n",
       " 'hepr': (['helper'], 0),\n",
       " 'regul': (['regular'], 0),\n",
       " 'prability': (['probability'], 0),\n",
       " 'nfamliar': (['unfamiliar'], 0),\n",
       " 'barque': ([], 3),\n",
       " 'regua': (['regular'], 0),\n",
       " 'doubtn': (['doubting'], 0),\n",
       " 'conciliaig': (['conciliating'], 0),\n",
       " 'doubti': (['doubting'], 0),\n",
       " 'obest': (['noblest'], 0),\n",
       " 'pewrite': (['typewrite'], 0),\n",
       " 'bnorml': (['abnormal'], 0),\n",
       " 'hepe': (['helper', 'helped', 'heaped'], 0),\n",
       " 'hepd': (['helped', 'heaped'], 0),\n",
       " 'doubtr': (['doubter'], 0),\n",
       " 'doubts': ([], 8),\n",
       " 'steathil': (['stealthily'], 0),\n",
       " 'opefl': (['hopeful'], 0),\n",
       " 'regur': (['regular'], 0),\n",
       " 'ldgings': (['lodgings'], 0),\n",
       " 'stnished': (['astonished'], 0),\n",
       " 'confscted': (['confiscated'], 0),\n",
       " 'bnorma': (['abnormal'], 0),\n",
       " 'intad': (['instead'], 0),\n",
       " 'andlors': (['landlords'], 0),\n",
       " 'oscillted': (['oscillated'], 0),\n",
       " 'sreted': (['secreted'], 0),\n",
       " 'eedle': (['needle'], 0),\n",
       " 'decrbe': (['describe'], 0),\n",
       " 'intal': (['initial'], 0),\n",
       " 'intan': (['instant'], 0),\n",
       " 'reulive': (['repulsive'], 0),\n",
       " 'professionally': ([], 1),\n",
       " 'fulfilmen': (['fulfilment'], 0),\n",
       " 'jacsn': (['jackson'], 0),\n",
       " 'intat': (['instant', 'intact'], 0),\n",
       " 'oscilltes': (['oscillates'], 0),\n",
       " 'andlord': (['landlord', 'landlords'], 0),\n",
       " 'outwest': (['southwest'], 0),\n",
       " 'rukard': (['drunkard'], 0),\n",
       " 'nimatio': (['animation'], 0),\n",
       " 'nimatin': (['animation'], 0),\n",
       " 'droppig': (['dropping'], 0),\n",
       " 'tuscaoras': (['tuscaroras'], 0),\n",
       " 'rooke': (['provoke'], 0),\n",
       " 'magnificet': (['magnificent'], 0),\n",
       " 'unor': (['junior'], 0),\n",
       " 'deste': (['despite'], 0),\n",
       " 'hypothsi': (['hypothesis'], 0),\n",
       " 'desti': (['destiny'], 0),\n",
       " 'prtsdwn': (['portsdown'], 0),\n",
       " 'desto': (['destroy'], 0),\n",
       " 'destn': (['destiny'], 0),\n",
       " 'anger': (['manager', 'danger', 'dangers', 'rangers'], 11),\n",
       " 'dests': (['deserts'], 0),\n",
       " 'destr': (['destroy'], 0),\n",
       " 'conjecued': (['conjectured'], 0),\n",
       " 'povety': (['poverty'], 0),\n",
       " 'desty': (['destroy', 'destiny'], 0),\n",
       " 'emciaion': (['emaciation'], 0),\n",
       " 'hypothss': (['hypothesis'], 0),\n",
       " 'unon': (['union'], 0),\n",
       " 'sustantia': (['substantial'], 0),\n",
       " 'shredl': (['shrewdly'], 0),\n",
       " 'memorial': (['memorials'], 0),\n",
       " 'ovecot': (['overcoat'], 0),\n",
       " 'enforcements': (['reinforcements'], 0),\n",
       " 'monrchst': (['monarchist'], 0),\n",
       " 'remane': (['remained', 'remanded'], 0),\n",
       " 'remand': (['remained', 'remanded'], 0),\n",
       " 'outnmbred': (['outnumbered'], 0),\n",
       " 'explaation': (['explanation', 'explanations'], 0),\n",
       " 'represnting': (['representing'], 0),\n",
       " 'doinions': (['dominions'], 0),\n",
       " 'explaatios': (['explanations'], 0),\n",
       " 'ovecoa': (['overcoat'], 0),\n",
       " 'braeets': (['bracelets'], 0),\n",
       " 'possibiltie': (['possibilities'], 0),\n",
       " 'ovecoe': (['overcome'], 0),\n",
       " 'revoltions': (['revolutions'], 0),\n",
       " 'submittig': (['submitting'], 0),\n",
       " 'indipoition': (['indisposition'], 0),\n",
       " 'sympathi': (['sympathies'], 0),\n",
       " 'drochloric': (['hydrochloric'], 0),\n",
       " 'remans': (['remains'], 0),\n",
       " 'sarpet': (['sharpest'], 0),\n",
       " 'penazed': (['penalized'], 0),\n",
       " 'ssgned': (['assigned'], 0),\n",
       " 'eclusions': (['exclusions'], 0),\n",
       " 'determition': (['determination'], 0),\n",
       " 'tinction': (['extinction'], 0),\n",
       " 'zealan': (['zealand'], 0),\n",
       " 'comanion': (['companion', 'companions'], 0),\n",
       " 'iprovemnt': (['improvement'], 0),\n",
       " 'uncomrtable': (['uncomfortable'], 0),\n",
       " 'delhted': (['delighted'], 0),\n",
       " 'relcted': (['reflected'], 0),\n",
       " 'zealad': (['zealand'], 0),\n",
       " 'affetions': (['affections'], 0),\n",
       " 'suvert': (['subvert'], 0),\n",
       " 'bullts': (['bullets'], 0),\n",
       " 'orresponence': (['correspondence'], 0),\n",
       " 'comanios': (['companions'], 0),\n",
       " 'ensylvania': (['pennsylvania'], 0),\n",
       " 'ecnomiss': (['economists'], 0),\n",
       " 'thooughfae': (['thoroughfare'], 0),\n",
       " 'faihess': (['faithless'], 0),\n",
       " 'imloed': (['implored'], 0),\n",
       " 'cetor': (['creator'], 0),\n",
       " 'setarianim': (['sectarianism'], 0),\n",
       " 'victorie': (['victories'], 0),\n",
       " 'corporati': (['corporation'], 0),\n",
       " 'incidns': (['incidents'], 0),\n",
       " 'stillness': ([], 2),\n",
       " 'lonelier': ([], 1),\n",
       " 'incidnt': (['incidents', 'incident'], 0),\n",
       " 'thooughfar': (['thoroughfare'], 0),\n",
       " 'scintllaing': (['scintillating'], 0),\n",
       " 'embnment': (['embankment'], 0),\n",
       " 'corporate': (['incorporate'], 1),\n",
       " 'frnishig': (['furnishing'], 0),\n",
       " 'ewfoudland': (['newfoundland'], 0),\n",
       " 'provincal': (['provincial', 'provincials'], 0),\n",
       " 'despsed': (['despised'], 0),\n",
       " 'indusrous': (['industrious'], 0),\n",
       " 'stny': (['stony', 'stingy'], 0),\n",
       " 'nitive': (['punitive'], 0),\n",
       " 'repuics': (['republics'], 0),\n",
       " 'rndred': (['rendered'], 0),\n",
       " 'stns': (['stands', 'stones', 'stains'], 0),\n",
       " 'stnr': (['stoner'], 0),\n",
       " 'gneras': (['generals'], 0),\n",
       " 'delgtion': (['delegation'], 0),\n",
       " 'coordiate': (['coordinate'], 0),\n",
       " 'signifcnt': (['significant'], 0),\n",
       " 'pceeded': (['proceeded'], 0),\n",
       " 'istoians': (['historians'], 0),\n",
       " 'stni': (['standi'], 0),\n",
       " 'stnh': (['stanch'], 0),\n",
       " 'stng': (['strong', 'stingy', 'stung'], 0),\n",
       " 'handkechief': (['handkerchief', 'handkerchiefs'], 0),\n",
       " 'stne': (['stone', 'stones', 'stoner', 'stoned'], 0),\n",
       " 'stnd': (['stands', 'strand', 'stand', 'standi', 'stoned'], 0),\n",
       " 'stnc': (['stanch'], 0),\n",
       " 'admnistraions': (['administrations'], 0),\n",
       " 'provincas': (['provincials'], 0),\n",
       " 'manifeto': (['manifesto'], 0),\n",
       " 'persuasis': (['persuasions'], 0),\n",
       " 'ristocacy': (['aristocracy'], 0),\n",
       " 'frderik': (['frederick'], 0),\n",
       " 'considerton': (['consideration'], 0),\n",
       " 'desposm': (['despotism'], 0),\n",
       " 'contmprary': (['contemporary'], 0),\n",
       " 'comonwealths': (['commonwealths'], 0),\n",
       " 'sstitute': (['substitute'], 0),\n",
       " 'disputaious': (['disputatious'], 0),\n",
       " 'convenionaities': (['conventionalities'], 0),\n",
       " 'explots': (['exploits'], 0),\n",
       " 'shiig': (['shining'], 0),\n",
       " 'disliing': (['disliking'], 0),\n",
       " 'diferenes': (['differences'], 0),\n",
       " 'memrils': (['memorials'], 0),\n",
       " 'eatness': (['exactness', 'neatness', 'greatness'], 0),\n",
       " 'persuasin': (['persuasions'], 0),\n",
       " 'shiin': (['shining'], 0),\n",
       " 'constittionlly': (['constitutionally'], 0),\n",
       " ...}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dameraulevenshtein(seq1, seq2):\n",
    "    \"\"\"Calculate the Damerau-Levenshtein distance between sequences.\n",
    "\n",
    "    Source: http://mwh.geek.nz/2009/04/26/python-damerau-levenshtein-distance/\n",
    "    \n",
    "    This distance is the number of additions, deletions, substitutions,\n",
    "    and transpositions needed to transform the first sequence into the\n",
    "    second. Although generally used with strings, any sequences of\n",
    "    comparable objects will work.\n",
    "\n",
    "    Transpositions are exchanges of *consecutive* characters; all other\n",
    "    operations are self-explanatory.\n",
    "\n",
    "    This implementation is O(N*M) time and O(M) space, for N and M the\n",
    "    lengths of the two sequences.\n",
    "\n",
    "    >>> dameraulevenshtein('ba', 'abc')\n",
    "    2\n",
    "    >>> dameraulevenshtein('fee', 'deed')\n",
    "    2\n",
    "\n",
    "    It works with arbitrary sequences too:\n",
    "    >>> dameraulevenshtein('abcd', ['b', 'a', 'c', 'd', 'e'])\n",
    "    2\n",
    "    \"\"\"\n",
    "    # codesnippet:D0DE4716-B6E6-4161-9219-2903BF8F547F\n",
    "    # Conceptually, this is based on a len(seq1) + 1 * len(seq2) + 1 matrix.\n",
    "    # However, only the current and two previous rows are needed at once,\n",
    "    # so we only store those.\n",
    "    oneago = None\n",
    "    thisrow = range(1, len(seq2) + 1) + [0]\n",
    "    for x in xrange(len(seq1)):\n",
    "        # Python lists wrap around for negative indices, so put the\n",
    "        # leftmost column at the *end* of the list. This matches with\n",
    "        # the zero-indexed strings and saves extra calculation.\n",
    "        twoago, oneago, thisrow = oneago, thisrow, [0] * len(seq2) + [x + 1]\n",
    "        for y in xrange(len(seq2)):\n",
    "            delcost = oneago[y] + 1\n",
    "            addcost = thisrow[y - 1] + 1\n",
    "            subcost = oneago[y - 1] + (seq1[x] != seq2[y])\n",
    "            thisrow[y] = min(delcost, addcost, subcost)\n",
    "            # This block deals with transpositions\n",
    "            if (x > 0 and y > 0 and seq1[x] == seq2[y - 1]\n",
    "                and seq1[x-1] == seq2[y] and seq1[x] != seq2[y]):\n",
    "                thisrow[y] = min(thisrow[y], twoago[y - 2] + 1)\n",
    "    return thisrow[len(seq2) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_suggestions(string):\n",
    "    '''return list of suggested corrections for potentially incorrectly spelled word'''\n",
    "    if (len(string) - longest_word_length) > max_edit_distance:\n",
    "        print \"no items in dictionary within maximum edit distance\"\n",
    "        return []\n",
    "    \n",
    "    # suggestions = []\n",
    "    # s_dictionary = {}\n",
    "    suggest_dict = {}\n",
    "    \n",
    "    queue = [string]\n",
    "    q_dictionary = {}  # items other than string that we've checked\n",
    "    \n",
    "    while len(queue)>0:\n",
    "        q_item = queue[0]  # pop\n",
    "        # print \"processing '%s'\" % q_item\n",
    "        queue = queue[1:]\n",
    "        \n",
    "        # process queue item\n",
    "        if (q_item in dictionary) and (q_item not in suggest_dict):\n",
    "            if (dictionary[q_item][1]>0):\n",
    "            # word is in dictionary, and is a word from the corpus, and not already in suggestion list\n",
    "            # so add to suggestion dictionary, indexed by the word with value (frequency in corpus, edit distance)\n",
    "            # note q_items that are not the input string are shorter than input string \n",
    "            # since only deletes are added (unless manual dictionary corrections are added)\n",
    "                assert len(string)>=len(q_item)\n",
    "                suggest_dict[q_item] = (dictionary[q_item][1], len(string) - len(q_item))\n",
    "            \n",
    "            ## the suggested corrections for q_item as stored in dictionary (whether or not\n",
    "            ## q_item itself is a valid word or merely a delete) can be valid corrections\n",
    "            for sc_item in dictionary[q_item][0]:\n",
    "                if (sc_item not in suggest_dict):\n",
    "                    # compute edit distance\n",
    "                    # if len(sc_item)==len(q_item):\n",
    "                    #    item_dist = len(string) - len(q_item)\n",
    "                    # suggested items should always be longer (unless manual corrections are added)\n",
    "                    assert len(sc_item)>len(q_item)\n",
    "                    # q_items that are not input should be shorter than original string \n",
    "                    # (unless manual corrections added)\n",
    "                    assert len(q_item)<=len(string)\n",
    "                    if len(q_item)==len(string):\n",
    "                        assert q_item==string\n",
    "                        item_dist = len(sc_item) - len(q_item)\n",
    "                    #elif len(q_item)==len(string):\n",
    "                        # a suggestion could be longer or shorter than original string (bug in original FAROO?)\n",
    "                        # if suggestion is from string's suggestion list, sc_item will be longer\n",
    "                        # if suggestion is from a delete's suggestion list, sc_item may be shorter\n",
    "                    #   item_dist = abs(len(sc_item) - len(q_item))\n",
    "                    #else:\n",
    "                    # check in original code, but probably not necessary because string has already checked\n",
    "                    assert sc_item!=string\n",
    "                    \n",
    "                    # calculate edit distance using, for example, Damerau-Levenshtein distance\n",
    "                    item_dist = dameraulevenshtein(sc_item, string)\n",
    "                    \n",
    "                    if item_dist<=max_edit_distance:\n",
    "                        assert sc_item in dictionary  # should already be in dictionary if in suggestion list\n",
    "                        suggest_dict[sc_item] = (dictionary[sc_item][1], item_dist)\n",
    "        \n",
    "        # now generate deletes (e.g. a substring of string or of a delete) from the queue item\n",
    "        # as additional items to check -- add to end of queue\n",
    "        assert len(string)>=len(q_item)\n",
    "        if (len(string)-len(q_item))<max_edit_distance and len(q_item)>1:\n",
    "            for c in range(len(q_item)): # character index        \n",
    "                word_minus_c = q_item[:c] + q_item[c+1:]\n",
    "                if word_minus_c not in q_dictionary:\n",
    "                    queue.append(word_minus_c)\n",
    "                    q_dictionary[word_minus_c] = None  # arbitrary value, just to identify we checked this\n",
    "             \n",
    "    # queue is now empty: convert suggestions in dictionary to list for output\n",
    "    \n",
    "    # output option 1\n",
    "    # sort results by ascending order of edit distance and descending order of frequency\n",
    "    #     and return list of suggested corrections only:\n",
    "    # return sorted(suggest_dict, key = lambda x: (suggest_dict[x][1], -suggest_dict[x][0]))\n",
    "\n",
    "    # output option 2\n",
    "    # return list of suggestions with (correction, (frequency in corpus, edit distance)):\n",
    "    as_list = suggest_dict.items()\n",
    "    return sorted(as_list, key = lambda (term, (freq, dist)): (dist, -freq))\n",
    "\n",
    "    '''\n",
    "    Option 1:\n",
    "    get_suggestions(\"file\")\n",
    "    ['file', 'five', 'fire', 'fine', ...]\n",
    "    \n",
    "    Option 2:\n",
    "    get_suggestions(\"file\")\n",
    "    [('file', (5, 0)),\n",
    "     ('five', (67, 1)),\n",
    "     ('fire', (54, 1)),\n",
    "     ('fine', (17, 1))...]  \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('whom', (51, 0)),\n",
       " ('who', (461, 1)),\n",
       " ('whim', (2, 1)),\n",
       " ('whoa', (2, 1)),\n",
       " ('from', (849, 2)),\n",
       " ('him', (486, 2)),\n",
       " ('what', (456, 2)),\n",
       " ('when', (443, 2)),\n",
       " ('them', (312, 2)),\n",
       " ('how', (197, 2)),\n",
       " ('room', (172, 2)),\n",
       " ('why', (98, 2)),\n",
       " ('whole', (81, 2)),\n",
       " ('home', (77, 2)),\n",
       " ('whose', (36, 2)),\n",
       " ('show', (29, 2)),\n",
       " ('won', (24, 2)),\n",
       " ('shot', (16, 2)),\n",
       " ('wood', (13, 2)),\n",
       " ('hot', (12, 2)),\n",
       " ('hum', (9, 2)),\n",
       " ('shop', (6, 2)),\n",
       " ('whip', (4, 2)),\n",
       " ('warm', (4, 2)),\n",
       " ('whig', (3, 2)),\n",
       " ('com', (2, 2)),\n",
       " ('htm', (1, 2)),\n",
       " ('shoe', (1, 2)),\n",
       " ('whit', (1, 2)),\n",
       " ('whims', (1, 2)),\n",
       " ('whoso', (1, 2)),\n",
       " ('wool', (1, 2)),\n",
       " ('doom', (1, 2)),\n",
       " ('worm', (1, 2))]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "get_suggestions(\"whom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
